{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amayuru1999/Number-Plate-Detection/blob/master/Automatic_Number_Plate_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUANWN3rpfC9"
      },
      "source": [
        "# 0. Setup Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "146BB11JpfDA"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42hJEdo_pfDB"
      },
      "outputs": [],
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbPhYVy_pfDB"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwhWZMI0pfDC"
      },
      "outputs": [],
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR-TfDGrpfDC"
      },
      "outputs": [],
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLU-rs_ipfDE"
      },
      "source": [
        "# 1. Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "begyeZOItr25"
      },
      "outputs": [],
      "source": [
        "# https://www.tensorflow.org/install/source_windows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-Cmz2edpfDE",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iA1DIq5OpfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "299e780a-a20f-431b-cde4-621a7dad3fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 90205, done.\u001b[K\n",
            "remote: Total 90205 (delta 0), reused 0 (delta 0), pack-reused 90205\u001b[K\n",
            "Receiving objects: 100% (90205/90205), 604.89 MiB | 32.52 MiB/s, done.\n",
            "Resolving deltas: 100% (65022/65022), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJjMHbnDs3Tv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca49f140-f60b-4382-ec17-98b485398e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "protobuf-compiler is already the newest version (3.12.4-1ubuntu7.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Processing /content/Tensorflow/models/research\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting avro-python3 (from object-detection==0.1)\n",
            "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting apache-beam (from object-detection==0.1)\n",
            "  Downloading apache_beam-2.52.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.6)\n",
            "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n",
            "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n",
            "Collecting lvis (from object-detection==0.1)\n",
            "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n",
            "Collecting tf-models-official>=2.5.1 (from object-detection==0.1)\n",
            "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n",
            "  Downloading tensorflow_io-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.15.0)\n",
            "Collecting pyparsing==2.4.7 (from object-detection==0.1)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sacrebleu<=2.2.0 (from object-detection==0.1)\n",
            "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.23.5)\n",
            "Collecting colorama (from sacrebleu<=2.2.0->object-detection==0.1)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.84.0)\n",
            "Collecting immutabledict (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading immutabledict-4.1.0-py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.16)\n",
            "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.8.1.78)\n",
            "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (9.0.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (6.0.1)\n",
            "Collecting sentencepiece (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seqeval (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.9.4)\n",
            "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.15.0)\n",
            "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-text~=2.15.0 (from tf-models-official>=2.5.1->object-detection==0.1)\n",
            "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object-detection==0.1) (2023.3.post1)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object-detection==0.1) (1.4.0)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting orjson<4,>=3.9.7 (from apache-beam->object-detection==0.1)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.2.1)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fastavro-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fasteners<1.0,>=0.3 (from apache-beam->object-detection==0.1)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.60.0)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (0.22.0)\n",
            "Collecting js2py<1,>=0.74 (from apache-beam->object-detection==0.1)\n",
            "  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.19.2)\n",
            "Collecting objsize<0.7.0,>=0.6.1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (23.2)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.23.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (3.20.3)\n",
            "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (4.5.0)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache-beam->object-detection==0.1)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow<12.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object-detection==0.1) (10.0.1)\n",
            "Collecting pyarrow-hotfix<1 (from apache-beam->object-detection==0.1)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (1.4.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object-detection==0.1) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object-detection==0.1) (4.46.0)\n",
            "Collecting tensorflow-io-gcs-filesystem==0.35.0 (from tensorflow_io->object-detection==0.1)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.35.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: google-auth<3.0.0dev,>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.11.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tzlocal>=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py<1,>=0.74->apache-beam->object-detection==0.1) (5.2)\n",
            "Collecting pyjsparser>=2.5.1 (from js2py<1,>=0.74->apache-beam->object-detection==0.1)\n",
            "  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object-detection==0.1) (0.15.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2023.11.17)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache-beam->object-detection==0.1)\n",
            "  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (3.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (67.7.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.15.0)\n",
            "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (8.1.7)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.6.0)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.14.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.42.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (6.1.1)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (3.17.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.62.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.0dev,>=1.19.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (5.3.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (2.1.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.2)\n",
            "Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697356 sha256=d8bd7a294b6135bcf18596763c5aa6add1c84c06c21be2f238de0d1001b1e4e8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ky0_n6c3/wheels/fb/c9/43/709f88e66b36649c7a29812ca4f6236f31caed949aabc3e335\n",
            "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=6f01ed315a6b61ea28af354c9eab18878c2d397e68d8c3158adaaa7da9cca029\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31407 sha256=0308bdc2081ae397f943b2964d0000442defce322c2f71b9d117a895a93187e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78540 sha256=f0c998bdb2008cc8f805a1b97ecd803aacb3a79db83b750126689175384cb45a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=da08721fa3551549f74feb4b907d6625361cf2b51e2e0f9cd481e1c98b724e17\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=c294a6da9ea596387a393230d2b9edd8ddc109e7ebdfdc8c6326937924e021c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=da7451fe7b2ee909025ab0b99af3f6b0fdb3ac1821ac5ff574a129756f3b0d20\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=de2de2e9762ddd07259bb70254a0563b4a76e71c9bda020250e85a1475ca5d05\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built object-detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n",
            "Installing collected packages: sentencepiece, pyjsparser, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow-io-gcs-filesystem, pyparsing, pyarrow-hotfix, portalocker, orjson, objsize, js2py, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, tensorflow_io, sacrebleu, pymongo, hdfs, seqeval, lvis, apache-beam, tensorflow-text, tf-models-official, object-detection\n",
            "  Attempting uninstall: tensorflow-io-gcs-filesystem\n",
            "    Found existing installation: tensorflow-io-gcs-filesystem 0.34.0\n",
            "    Uninstalling tensorflow-io-gcs-filesystem-0.34.0:\n",
            "      Successfully uninstalled tensorflow-io-gcs-filesystem-0.34.0\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "Successfully installed apache-beam-2.52.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.9.2 fasteners-0.19 hdfs-2.7.3 immutabledict-4.1.0 js2py-0.74 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.9.10 portalocker-2.8.2 pyarrow-hotfix-0.6 pyjsparser-2.7.1 pymongo-4.6.1 pyparsing-2.4.7 sacrebleu-2.2.0 sentencepiece-0.1.99 seqeval-1.2.2 tensorflow-io-gcs-filesystem-0.35.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tensorflow_io-0.35.0 tf-models-official-2.15.0 zstandard-0.22.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tensorflow Object Detection\n",
        "if os.name=='posix':\n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "\n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "n0azOlITtr26"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "gYEYynSDtr26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfdfb0c-746c-4288-d72a-cf57f2b44a54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-24 15:24:52.001651: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-12-24 15:24:52.197280: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-12-24 15:24:52.198152: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-24 15:24:57.074380: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Running tests under Python 3.10.12: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W1224 15:25:00.381867 139239975755776 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n",
            "W1224 15:25:00.898757 139239975755776 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.17s\n",
            "I1224 15:25:01.514421 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.17s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.1s\n",
            "I1224 15:25:02.617332 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 1.1s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.53s\n",
            "I1224 15:25:03.150208 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.53s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n",
            "I1224 15:25:03.579093 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.43s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 3.21s\n",
            "I1224 15:25:06.786273 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 3.21s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "I1224 15:25:06.792457 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "I1224 15:25:06.830669 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "I1224 15:25:06.855856 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "I1224 15:25:06.883018 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.03s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.15s\n",
            "I1224 15:25:07.034276 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "I1224 15:25:07.166834 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.13s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "I1224 15:25:07.311004 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "I1224 15:25:07.456053 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.14s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.15s\n",
            "I1224 15:25:07.603392 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.15s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "I1224 15:25:07.648001 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.04s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "I1224 15:25:07.901721 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
            "I1224 15:25:07.901901 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n",
            "I1224 15:25:07.901961 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n",
            "I1224 15:25:07.905472 139239975755776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1224 15:25:07.944964 139239975755776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1224 15:25:07.945186 139239975755776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1224 15:25:08.047380 139239975755776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1224 15:25:08.047575 139239975755776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1224 15:25:08.331496 139239975755776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1224 15:25:08.331691 139239975755776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1224 15:25:08.633993 139239975755776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1224 15:25:08.634220 139239975755776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1224 15:25:09.154462 139239975755776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1224 15:25:09.154680 139239975755776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1224 15:25:09.712259 139239975755776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1224 15:25:09.712498 139239975755776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1224 15:25:10.474705 139239975755776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1224 15:25:10.474944 139239975755776 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1224 15:25:10.690888 139239975755776 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1224 15:25:10.822589 139239975755776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 15:25:10.933065 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
            "I1224 15:25:10.933313 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n",
            "I1224 15:25:10.933394 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n",
            "I1224 15:25:10.937009 139239975755776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1224 15:25:10.969731 139239975755776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1224 15:25:10.969963 139239975755776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1224 15:25:11.227257 139239975755776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1224 15:25:11.227480 139239975755776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1224 15:25:11.742863 139239975755776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1224 15:25:11.743093 139239975755776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1224 15:25:12.532010 139239975755776 efficientnet_model.py:143] round_filter input=40 output=40\n",
            "I1224 15:25:12.532264 139239975755776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1224 15:25:13.202876 139239975755776 efficientnet_model.py:143] round_filter input=80 output=80\n",
            "I1224 15:25:13.203136 139239975755776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1224 15:25:13.881686 139239975755776 efficientnet_model.py:143] round_filter input=112 output=112\n",
            "I1224 15:25:13.881884 139239975755776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1224 15:25:14.560775 139239975755776 efficientnet_model.py:143] round_filter input=192 output=192\n",
            "I1224 15:25:14.560978 139239975755776 efficientnet_model.py:143] round_filter input=320 output=320\n",
            "I1224 15:25:14.891413 139239975755776 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
            "I1224 15:25:14.962610 139239975755776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 15:25:15.045994 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
            "I1224 15:25:15.046240 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n",
            "I1224 15:25:15.046350 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n",
            "I1224 15:25:15.048735 139239975755776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1224 15:25:15.073625 139239975755776 efficientnet_model.py:143] round_filter input=32 output=32\n",
            "I1224 15:25:15.073822 139239975755776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1224 15:25:15.270928 139239975755776 efficientnet_model.py:143] round_filter input=16 output=16\n",
            "I1224 15:25:15.271138 139239975755776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1224 15:25:15.634075 139239975755776 efficientnet_model.py:143] round_filter input=24 output=24\n",
            "I1224 15:25:15.634331 139239975755776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1224 15:25:16.034466 139239975755776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1224 15:25:16.034659 139239975755776 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1224 15:25:16.563926 139239975755776 efficientnet_model.py:143] round_filter input=80 output=88\n",
            "I1224 15:25:16.564131 139239975755776 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1224 15:25:17.133175 139239975755776 efficientnet_model.py:143] round_filter input=112 output=120\n",
            "I1224 15:25:17.133358 139239975755776 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1224 15:25:17.844698 139239975755776 efficientnet_model.py:143] round_filter input=192 output=208\n",
            "I1224 15:25:17.844890 139239975755776 efficientnet_model.py:143] round_filter input=320 output=352\n",
            "I1224 15:25:18.192829 139239975755776 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
            "I1224 15:25:18.278090 139239975755776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 15:25:18.367228 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
            "I1224 15:25:18.367422 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n",
            "I1224 15:25:18.367526 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n",
            "I1224 15:25:18.369971 139239975755776 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1224 15:25:18.401476 139239975755776 efficientnet_model.py:143] round_filter input=32 output=40\n",
            "I1224 15:25:18.401662 139239975755776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1224 15:25:18.611293 139239975755776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1224 15:25:18.611493 139239975755776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1224 15:25:18.989981 139239975755776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1224 15:25:18.990192 139239975755776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1224 15:25:19.351025 139239975755776 efficientnet_model.py:143] round_filter input=40 output=48\n",
            "I1224 15:25:19.351226 139239975755776 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1224 15:25:19.999069 139239975755776 efficientnet_model.py:143] round_filter input=80 output=96\n",
            "I1224 15:25:19.999323 139239975755776 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1224 15:25:20.655848 139239975755776 efficientnet_model.py:143] round_filter input=112 output=136\n",
            "I1224 15:25:20.656039 139239975755776 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1224 15:25:21.552375 139239975755776 efficientnet_model.py:143] round_filter input=192 output=232\n",
            "I1224 15:25:21.552574 139239975755776 efficientnet_model.py:143] round_filter input=320 output=384\n",
            "I1224 15:25:21.902486 139239975755776 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
            "I1224 15:25:21.986972 139239975755776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 15:25:22.083457 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
            "I1224 15:25:22.083637 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n",
            "I1224 15:25:22.083697 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1224 15:25:22.086043 139239975755776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1224 15:25:22.111366 139239975755776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1224 15:25:22.111552 139239975755776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1224 15:25:22.299135 139239975755776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1224 15:25:22.299325 139239975755776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1224 15:25:22.763744 139239975755776 efficientnet_model.py:143] round_filter input=24 output=32\n",
            "I1224 15:25:22.763927 139239975755776 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1224 15:25:23.271033 139239975755776 efficientnet_model.py:143] round_filter input=40 output=56\n",
            "I1224 15:25:23.271258 139239975755776 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1224 15:25:24.679894 139239975755776 efficientnet_model.py:143] round_filter input=80 output=112\n",
            "I1224 15:25:24.680124 139239975755776 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1224 15:25:25.890472 139239975755776 efficientnet_model.py:143] round_filter input=112 output=160\n",
            "I1224 15:25:25.890706 139239975755776 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1224 15:25:27.727392 139239975755776 efficientnet_model.py:143] round_filter input=192 output=272\n",
            "I1224 15:25:27.727623 139239975755776 efficientnet_model.py:143] round_filter input=320 output=448\n",
            "I1224 15:25:28.301438 139239975755776 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
            "I1224 15:25:28.446577 139239975755776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 15:25:28.619138 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
            "I1224 15:25:28.619366 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n",
            "I1224 15:25:28.619449 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n",
            "I1224 15:25:28.623036 139239975755776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1224 15:25:28.661615 139239975755776 efficientnet_model.py:143] round_filter input=32 output=48\n",
            "I1224 15:25:28.661843 139239975755776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1224 15:25:29.012153 139239975755776 efficientnet_model.py:143] round_filter input=16 output=24\n",
            "I1224 15:25:29.012338 139239975755776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1224 15:25:29.652460 139239975755776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1224 15:25:29.652646 139239975755776 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1224 15:25:30.293802 139239975755776 efficientnet_model.py:143] round_filter input=40 output=64\n",
            "I1224 15:25:30.293989 139239975755776 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1224 15:25:31.237375 139239975755776 efficientnet_model.py:143] round_filter input=80 output=128\n",
            "I1224 15:25:31.237567 139239975755776 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1224 15:25:32.183892 139239975755776 efficientnet_model.py:143] round_filter input=112 output=176\n",
            "I1224 15:25:32.184074 139239975755776 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1224 15:25:33.584734 139239975755776 efficientnet_model.py:143] round_filter input=192 output=304\n",
            "I1224 15:25:33.584935 139239975755776 efficientnet_model.py:143] round_filter input=320 output=512\n",
            "I1224 15:25:34.210410 139239975755776 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
            "I1224 15:25:34.308690 139239975755776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 15:25:34.429131 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
            "I1224 15:25:34.429319 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1224 15:25:34.429405 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1224 15:25:34.431888 139239975755776 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1224 15:25:34.463825 139239975755776 efficientnet_model.py:143] round_filter input=32 output=56\n",
            "I1224 15:25:34.464007 139239975755776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1224 15:25:34.755878 139239975755776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1224 15:25:34.756066 139239975755776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1224 15:25:35.449074 139239975755776 efficientnet_model.py:143] round_filter input=24 output=40\n",
            "I1224 15:25:35.449271 139239975755776 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1224 15:25:36.183902 139239975755776 efficientnet_model.py:143] round_filter input=40 output=72\n",
            "I1224 15:25:36.184079 139239975755776 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1224 15:25:37.612051 139239975755776 efficientnet_model.py:143] round_filter input=80 output=144\n",
            "I1224 15:25:37.612259 139239975755776 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1224 15:25:38.782705 139239975755776 efficientnet_model.py:143] round_filter input=112 output=200\n",
            "I1224 15:25:38.782907 139239975755776 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1224 15:25:41.630038 139239975755776 efficientnet_model.py:143] round_filter input=192 output=344\n",
            "I1224 15:25:41.630289 139239975755776 efficientnet_model.py:143] round_filter input=320 output=576\n",
            "I1224 15:25:42.717207 139239975755776 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
            "I1224 15:25:42.885695 139239975755776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "I1224 15:25:43.130315 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
            "I1224 15:25:43.130542 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n",
            "I1224 15:25:43.130627 139239975755776 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n",
            "I1224 15:25:43.134128 139239975755776 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1224 15:25:43.168471 139239975755776 efficientnet_model.py:143] round_filter input=32 output=64\n",
            "I1224 15:25:43.168691 139239975755776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1224 15:25:43.719025 139239975755776 efficientnet_model.py:143] round_filter input=16 output=32\n",
            "I1224 15:25:43.719260 139239975755776 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1224 15:25:44.695783 139239975755776 efficientnet_model.py:143] round_filter input=24 output=48\n",
            "I1224 15:25:44.695977 139239975755776 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1224 15:25:45.652738 139239975755776 efficientnet_model.py:143] round_filter input=40 output=80\n",
            "I1224 15:25:45.652958 139239975755776 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1224 15:25:47.023918 139239975755776 efficientnet_model.py:143] round_filter input=80 output=160\n",
            "I1224 15:25:47.024125 139239975755776 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1224 15:25:48.448569 139239975755776 efficientnet_model.py:143] round_filter input=112 output=224\n",
            "I1224 15:25:48.448760 139239975755776 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1224 15:25:50.707709 139239975755776 efficientnet_model.py:143] round_filter input=192 output=384\n",
            "I1224 15:25:50.707903 139239975755776 efficientnet_model.py:143] round_filter input=320 output=640\n",
            "I1224 15:25:51.757937 139239975755776 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
            "I1224 15:25:51.877753 139239975755776 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 44.39s\n",
            "I1224 15:25:52.040544 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 44.39s\n",
            "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "I1224 15:25:52.081010 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "I1224 15:25:52.083306 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "I1224 15:25:52.084069 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "I1224 15:25:52.085878 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTF2Test.test_session\n",
            "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "I1224 15:25:52.087387 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "I1224 15:25:52.087842 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "I1224 15:25:52.088940 139239975755776 test_util.py:2462] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
            "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 24 tests in 51.746s\n",
            "\n",
            "OK (skipped=1)\n"
          ]
        }
      ],
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rueIeipCtr27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c27f313e-1bc7-47d8-eb36-1be5de1477c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.4.1 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.4.1\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow==2.4.1 tensorflow-gpu==2.4.1 --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mjr3u_vKtr27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "outputId": "7596dd1f-a147-458c-d12d-1a4f16d38383"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: protobuf 4.25.1\n",
            "Uninstalling protobuf-4.25.1:\n",
            "  Successfully uninstalled protobuf-4.25.1\n",
            "Found existing installation: matplotlib 3.2.0\n",
            "Uninstalling matplotlib-3.2.0:\n",
            "  Successfully uninstalled matplotlib-3.2.0\n",
            "Collecting protobuf\n",
            "  Using cached protobuf-4.25.1-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "Collecting matplotlib==3.2\n",
            "  Using cached matplotlib-3.2.0-cp310-cp310-linux_x86_64.whl\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2) (1.23.5)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib==3.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.1->matplotlib==3.2) (1.16.0)\n",
            "Installing collected packages: protobuf, matplotlib\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "mizani 0.9.3 requires matplotlib>=3.5.0, but you have matplotlib 3.2.0 which is incompatible.\n",
            "plotnine 0.12.4 requires matplotlib>=3.6.0, but you have matplotlib 3.2.0 which is incompatible.\n",
            "tensorboard 2.15.1 requires protobuf<4.24,>=3.19.6, but you have protobuf 4.25.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed matplotlib-3.2.0 protobuf-4.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip uninstall protobuf matplotlib -y\n",
        "!pip install protobuf matplotlib==3.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A38hgQ_7tr27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba905286-0017-4152-f691-d8dc12b3a683"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install Pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktUw2Bo0tr27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f36333f6-34d1-4c61-f003-034a14f8609a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyyaml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGrZDkjdtr27"
      },
      "outputs": [],
      "source": [
        "!pip list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmPTw0Zjtr27"
      },
      "outputs": [],
      "source": [
        "import object_detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csofht2npfDE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d7ff34-e741-493e-ba0c-dd25aed787c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-24 15:02:47--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.16.207, 172.253.62.207, 142.251.163.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.16.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-12-24 15:02:47 (150 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ],
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5KJTnkfpfDC"
      },
      "source": [
        "# 2. Create Label Map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1BVDWo7pfDC"
      },
      "outputs": [],
      "source": [
        "labels = [{'name':'licence', 'id':1}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C88zyVELpfDC"
      },
      "source": [
        "# 3. Create TF records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvf5WccwrFGq"
      },
      "outputs": [],
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWpb_BVUpfDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5057b991-3c84-4910-dbe7-99c369fe531d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects:  33% (1/3)\u001b[K\rremote: Counting objects:  66% (2/3)\u001b[K\rremote: Counting objects: 100% (3/3)\u001b[K\rremote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects:  33% (1/3)\rReceiving objects:  66% (2/3)\rReceiving objects: 100% (3/3)\rReceiving objects: 100% (3/3), done.\n"
          ]
        }
      ],
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-3QAAottr28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e804a36-3576-4146-d4be-e46d1d772035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (2023.3.post1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pytz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UPFToGZqpfDD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92e83c01-3f14-4aaf-e312-9c8e107d79ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-24 15:05:23.015794: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-24 15:05:23.015866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-24 15:05:23.017528: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "2023-12-24 15:05:28.736035: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-24 15:05:28.736111: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-24 15:05:28.737514: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ],
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qT4QU7pLpfDE"
      },
      "source": [
        "# 4. Copy Model Config to Training Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cOjuTFbwpfDF"
      },
      "outputs": [],
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga8gpNslpfDF"
      },
      "source": [
        "# 5. Update Config For Transfer Learning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9hRrO_ppfDF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2A0mn4ipfDF"
      },
      "outputs": [],
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQA13-afpfDF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "741fafde-85b5-4220-92d8-f207022664de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': ssd {\n",
              "   num_classes: 90\n",
              "   image_resizer {\n",
              "     fixed_shape_resizer {\n",
              "       height: 320\n",
              "       width: 320\n",
              "     }\n",
              "   }\n",
              "   feature_extractor {\n",
              "     type: \"ssd_mobilenet_v2_fpn_keras\"\n",
              "     depth_multiplier: 1.0\n",
              "     min_depth: 16\n",
              "     conv_hyperparams {\n",
              "       regularizer {\n",
              "         l2_regularizer {\n",
              "           weight: 3.9999998989515007e-05\n",
              "         }\n",
              "       }\n",
              "       initializer {\n",
              "         random_normal_initializer {\n",
              "           mean: 0.0\n",
              "           stddev: 0.009999999776482582\n",
              "         }\n",
              "       }\n",
              "       activation: RELU_6\n",
              "       batch_norm {\n",
              "         decay: 0.996999979019165\n",
              "         scale: true\n",
              "         epsilon: 0.0010000000474974513\n",
              "       }\n",
              "     }\n",
              "     use_depthwise: true\n",
              "     override_base_feature_extractor_hyperparams: true\n",
              "     fpn {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       additional_layer_depth: 128\n",
              "     }\n",
              "   }\n",
              "   box_coder {\n",
              "     faster_rcnn_box_coder {\n",
              "       y_scale: 10.0\n",
              "       x_scale: 10.0\n",
              "       height_scale: 5.0\n",
              "       width_scale: 5.0\n",
              "     }\n",
              "   }\n",
              "   matcher {\n",
              "     argmax_matcher {\n",
              "       matched_threshold: 0.5\n",
              "       unmatched_threshold: 0.5\n",
              "       ignore_thresholds: false\n",
              "       negatives_lower_than_unmatched: true\n",
              "       force_match_for_each_row: true\n",
              "       use_matmul_gather: true\n",
              "     }\n",
              "   }\n",
              "   similarity_calculator {\n",
              "     iou_similarity {\n",
              "     }\n",
              "   }\n",
              "   box_predictor {\n",
              "     weight_shared_convolutional_box_predictor {\n",
              "       conv_hyperparams {\n",
              "         regularizer {\n",
              "           l2_regularizer {\n",
              "             weight: 3.9999998989515007e-05\n",
              "           }\n",
              "         }\n",
              "         initializer {\n",
              "           random_normal_initializer {\n",
              "             mean: 0.0\n",
              "             stddev: 0.009999999776482582\n",
              "           }\n",
              "         }\n",
              "         activation: RELU_6\n",
              "         batch_norm {\n",
              "           decay: 0.996999979019165\n",
              "           scale: true\n",
              "           epsilon: 0.0010000000474974513\n",
              "         }\n",
              "       }\n",
              "       depth: 128\n",
              "       num_layers_before_predictor: 4\n",
              "       kernel_size: 3\n",
              "       class_prediction_bias_init: -4.599999904632568\n",
              "       share_prediction_tower: true\n",
              "       use_depthwise: true\n",
              "     }\n",
              "   }\n",
              "   anchor_generator {\n",
              "     multiscale_anchor_generator {\n",
              "       min_level: 3\n",
              "       max_level: 7\n",
              "       anchor_scale: 4.0\n",
              "       aspect_ratios: 1.0\n",
              "       aspect_ratios: 2.0\n",
              "       aspect_ratios: 0.5\n",
              "       scales_per_octave: 2\n",
              "     }\n",
              "   }\n",
              "   post_processing {\n",
              "     batch_non_max_suppression {\n",
              "       score_threshold: 9.99999993922529e-09\n",
              "       iou_threshold: 0.6000000238418579\n",
              "       max_detections_per_class: 100\n",
              "       max_total_detections: 100\n",
              "       use_static_shapes: false\n",
              "     }\n",
              "     score_converter: SIGMOID\n",
              "   }\n",
              "   normalize_loss_by_num_matches: true\n",
              "   loss {\n",
              "     localization_loss {\n",
              "       weighted_smooth_l1 {\n",
              "       }\n",
              "     }\n",
              "     classification_loss {\n",
              "       weighted_sigmoid_focal {\n",
              "         gamma: 2.0\n",
              "         alpha: 0.25\n",
              "       }\n",
              "     }\n",
              "     classification_weight: 1.0\n",
              "     localization_weight: 1.0\n",
              "   }\n",
              "   encode_background_as_zeros: true\n",
              "   normalize_loc_loss_by_codesize: true\n",
              "   inplace_batchnorm_update: true\n",
              "   freeze_batchnorm: false\n",
              " },\n",
              " 'train_config': batch_size: 128\n",
              " data_augmentation_options {\n",
              "   random_horizontal_flip {\n",
              "   }\n",
              " }\n",
              " data_augmentation_options {\n",
              "   random_crop_image {\n",
              "     min_object_covered: 0.0\n",
              "     min_aspect_ratio: 0.75\n",
              "     max_aspect_ratio: 3.0\n",
              "     min_area: 0.75\n",
              "     max_area: 1.0\n",
              "     overlap_thresh: 0.0\n",
              "   }\n",
              " }\n",
              " sync_replicas: true\n",
              " optimizer {\n",
              "   momentum_optimizer {\n",
              "     learning_rate {\n",
              "       cosine_decay_learning_rate {\n",
              "         learning_rate_base: 0.07999999821186066\n",
              "         total_steps: 50000\n",
              "         warmup_learning_rate: 0.026666000485420227\n",
              "         warmup_steps: 1000\n",
              "       }\n",
              "     }\n",
              "     momentum_optimizer_value: 0.8999999761581421\n",
              "   }\n",
              "   use_moving_average: false\n",
              " }\n",
              " fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
              " num_steps: 50000\n",
              " startup_delay_steps: 0.0\n",
              " replicas_to_aggregate: 8\n",
              " max_number_of_boxes: 100\n",
              " unpad_groundtruth_tensors: false\n",
              " fine_tune_checkpoint_type: \"classification\"\n",
              " fine_tune_checkpoint_version: V2,\n",
              " 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " },\n",
              " 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
              " use_moving_averages: false,\n",
              " 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }\n",
              " ],\n",
              " 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " shuffle: false\n",
              " num_epochs: 1\n",
              " tf_record_input_reader {\n",
              "   input_path: \"PATH_TO_BE_CONFIGURED\"\n",
              " }}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vK5lotDpfDF"
      },
      "outputs": [],
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rP43Ph0JpfDG"
      },
      "outputs": [],
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJvfgwWqpfDG"
      },
      "outputs": [],
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zr3ON7xMpfDG"
      },
      "source": [
        "# 6. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Y2UQmQpfDG"
      },
      "outputs": [],
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMP2XDfQpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=10000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4OXXi-ApfDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb06106-bc5a-4514-fe9e-fa150eb24438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=10000\n"
          ]
        }
      ],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.13.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bJ6UFqO1a95s",
        "outputId": "339b0e4d-ab1a-48a1-e54c-bdc9e247022b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.13.0\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.1.21 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.5.26)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.13.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.60.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.9.0)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow==2.13.0)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (16.0.6)\n",
            "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.16.0)\n",
            "Collecting tensorboard<2.14,>=2.13 (from tensorflow==2.13.0)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow==2.13.0)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (4.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.13.0) (0.35.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.13.0) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.17.3)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow==2.13.0)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow==2.13.0) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, gast, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.15.0\n",
            "    Uninstalling tensorflow-estimator-2.15.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.15.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.15.0\n",
            "    Uninstalling keras-2.15.0:\n",
            "      Successfully uninstalled keras-2.15.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.5.4\n",
            "    Uninstalling gast-0.5.4:\n",
            "      Successfully uninstalled gast-0.5.4\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.0\n",
            "    Uninstalling google-auth-oauthlib-1.2.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.15.1\n",
            "    Uninstalling tensorboard-2.15.1:\n",
            "      Successfully uninstalled tensorboard-2.15.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.15.0\n",
            "    Uninstalling tensorflow-2.15.0:\n",
            "      Successfully uninstalled tensorflow-2.15.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-text 2.15.0 requires tensorflow<2.16,>=2.15.0; platform_machine != \"arm64\" or platform_system != \"Darwin\", but you have tensorflow 2.13.0 which is incompatible.\n",
            "tf-models-official 2.15.0 requires tensorflow~=2.15.0, but you have tensorflow 2.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 keras-2.13.1 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-estimator-2.13.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "keras",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3ZsJR-qpfDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90870aca-59c7-48da-9e15-1c5966fee33f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-12-24 15:26:13.100364: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-12-24 15:26:13.304571: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2023-12-24 15:26:13.306217: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-12-24 15:26:16.271731: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "I1224 15:26:22.216461 132534240645120 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 10000\n",
            "I1224 15:26:22.256517 132534240645120 config_util.py:552] Maybe overwriting train_steps: 10000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I1224 15:26:22.256777 132534240645120 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W1224 15:26:22.306290 132534240645120 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1224 15:26:22.318443 132534240645120 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I1224 15:26:22.318856 132534240645120 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I1224 15:26:22.318968 132534240645120 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W1224 15:26:22.319050 132534240645120 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W1224 15:26:22.330465 132534240645120 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W1224 15:26:22.363874 132534240645120 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W1224 15:26:31.398191 132534240645120 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W1224 15:26:34.551125 132534240645120 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W1224 15:26:37.211386 132534240645120 deprecation.py:364] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2023-12-24 15:26:41.569516: W tensorflow/core/framework/dataset.cc:956] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
            "  warnings.warn(\n",
            "I1224 15:26:52.246731 132531659720256 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I1224 15:27:03.515692 132531659720256 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "W1224 15:27:12.429816 132531965453888 deprecation.py:569] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use fn_output_signature instead\n",
            "I1224 15:27:13.819369 132531965453888 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I1224 15:27:20.469720 132531965453888 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I1224 15:27:27.904666 132531965453888 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "I1224 15:27:34.521232 132531965453888 api.py:460] feature_map_spatial_dims: [(40, 40), (20, 20), (10, 10), (5, 5), (3, 3)]\n",
            "INFO:tensorflow:Step 100 per-step time 2.044s\n",
            "I1224 15:30:36.424166 132534240645120 model_lib_v2.py:705] Step 100 per-step time 2.044s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.57889533,\n",
            " 'Loss/localization_loss': 0.53399897,\n",
            " 'Loss/regularization_loss': 0.15457538,\n",
            " 'Loss/total_loss': 1.2674696,\n",
            " 'learning_rate': 0.0319994}\n",
            "I1224 15:30:36.424741 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.57889533,\n",
            " 'Loss/localization_loss': 0.53399897,\n",
            " 'Loss/regularization_loss': 0.15457538,\n",
            " 'Loss/total_loss': 1.2674696,\n",
            " 'learning_rate': 0.0319994}\n",
            "INFO:tensorflow:Step 200 per-step time 1.568s\n",
            "I1224 15:33:13.174595 132534240645120 model_lib_v2.py:705] Step 200 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.4304479,\n",
            " 'Loss/localization_loss': 0.40647087,\n",
            " 'Loss/regularization_loss': 0.15474464,\n",
            " 'Loss/total_loss': 0.99166346,\n",
            " 'learning_rate': 0.0373328}\n",
            "I1224 15:33:13.174988 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.4304479,\n",
            " 'Loss/localization_loss': 0.40647087,\n",
            " 'Loss/regularization_loss': 0.15474464,\n",
            " 'Loss/total_loss': 0.99166346,\n",
            " 'learning_rate': 0.0373328}\n",
            "INFO:tensorflow:Step 300 per-step time 1.592s\n",
            "I1224 15:35:52.413462 132534240645120 model_lib_v2.py:705] Step 300 per-step time 1.592s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.46110028,\n",
            " 'Loss/localization_loss': 0.36331117,\n",
            " 'Loss/regularization_loss': 0.1548346,\n",
            " 'Loss/total_loss': 0.9792461,\n",
            " 'learning_rate': 0.0426662}\n",
            "I1224 15:35:52.414549 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.46110028,\n",
            " 'Loss/localization_loss': 0.36331117,\n",
            " 'Loss/regularization_loss': 0.1548346,\n",
            " 'Loss/total_loss': 0.9792461,\n",
            " 'learning_rate': 0.0426662}\n",
            "INFO:tensorflow:Step 400 per-step time 1.593s\n",
            "I1224 15:38:31.760327 132534240645120 model_lib_v2.py:705] Step 400 per-step time 1.593s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.192683,\n",
            " 'Loss/localization_loss': 0.290554,\n",
            " 'Loss/regularization_loss': 0.15490527,\n",
            " 'Loss/total_loss': 0.6381422,\n",
            " 'learning_rate': 0.047999598}\n",
            "I1224 15:38:31.760780 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.192683,\n",
            " 'Loss/localization_loss': 0.290554,\n",
            " 'Loss/regularization_loss': 0.15490527,\n",
            " 'Loss/total_loss': 0.6381422,\n",
            " 'learning_rate': 0.047999598}\n",
            "INFO:tensorflow:Step 500 per-step time 1.599s\n",
            "I1224 15:41:11.661035 132534240645120 model_lib_v2.py:705] Step 500 per-step time 1.599s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.26181665,\n",
            " 'Loss/localization_loss': 0.32578188,\n",
            " 'Loss/regularization_loss': 0.15492944,\n",
            " 'Loss/total_loss': 0.74252796,\n",
            " 'learning_rate': 0.053333}\n",
            "I1224 15:41:11.661468 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.26181665,\n",
            " 'Loss/localization_loss': 0.32578188,\n",
            " 'Loss/regularization_loss': 0.15492944,\n",
            " 'Loss/total_loss': 0.74252796,\n",
            " 'learning_rate': 0.053333}\n",
            "INFO:tensorflow:Step 600 per-step time 1.576s\n",
            "I1224 15:43:49.289173 132534240645120 model_lib_v2.py:705] Step 600 per-step time 1.576s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16846992,\n",
            " 'Loss/localization_loss': 0.20959891,\n",
            " 'Loss/regularization_loss': 0.15494765,\n",
            " 'Loss/total_loss': 0.5330165,\n",
            " 'learning_rate': 0.0586664}\n",
            "I1224 15:43:49.289633 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.16846992,\n",
            " 'Loss/localization_loss': 0.20959891,\n",
            " 'Loss/regularization_loss': 0.15494765,\n",
            " 'Loss/total_loss': 0.5330165,\n",
            " 'learning_rate': 0.0586664}\n",
            "INFO:tensorflow:Step 700 per-step time 1.579s\n",
            "I1224 15:46:27.199866 132534240645120 model_lib_v2.py:705] Step 700 per-step time 1.579s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.69439566,\n",
            " 'Loss/localization_loss': 0.25345117,\n",
            " 'Loss/regularization_loss': 0.15509035,\n",
            " 'Loss/total_loss': 1.1029372,\n",
            " 'learning_rate': 0.0639998}\n",
            "I1224 15:46:27.200299 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.69439566,\n",
            " 'Loss/localization_loss': 0.25345117,\n",
            " 'Loss/regularization_loss': 0.15509035,\n",
            " 'Loss/total_loss': 1.1029372,\n",
            " 'learning_rate': 0.0639998}\n",
            "INFO:tensorflow:Step 800 per-step time 1.646s\n",
            "I1224 15:49:11.785557 132534240645120 model_lib_v2.py:705] Step 800 per-step time 1.646s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2092472,\n",
            " 'Loss/localization_loss': 0.19800672,\n",
            " 'Loss/regularization_loss': 0.15505223,\n",
            " 'Loss/total_loss': 0.56230617,\n",
            " 'learning_rate': 0.069333196}\n",
            "I1224 15:49:11.786016 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.2092472,\n",
            " 'Loss/localization_loss': 0.19800672,\n",
            " 'Loss/regularization_loss': 0.15505223,\n",
            " 'Loss/total_loss': 0.56230617,\n",
            " 'learning_rate': 0.069333196}\n",
            "INFO:tensorflow:Step 900 per-step time 1.577s\n",
            "I1224 15:51:49.435408 132534240645120 model_lib_v2.py:705] Step 900 per-step time 1.577s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17159712,\n",
            " 'Loss/localization_loss': 0.14664301,\n",
            " 'Loss/regularization_loss': 0.15514031,\n",
            " 'Loss/total_loss': 0.47338045,\n",
            " 'learning_rate': 0.074666604}\n",
            "I1224 15:51:49.435813 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.17159712,\n",
            " 'Loss/localization_loss': 0.14664301,\n",
            " 'Loss/regularization_loss': 0.15514031,\n",
            " 'Loss/total_loss': 0.47338045,\n",
            " 'learning_rate': 0.074666604}\n",
            "INFO:tensorflow:Step 1000 per-step time 1.622s\n",
            "I1224 15:54:31.650402 132534240645120 model_lib_v2.py:705] Step 1000 per-step time 1.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15309146,\n",
            " 'Loss/localization_loss': 0.18549311,\n",
            " 'Loss/regularization_loss': 0.15519567,\n",
            " 'Loss/total_loss': 0.49378026,\n",
            " 'learning_rate': 0.08}\n",
            "I1224 15:54:31.650920 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.15309146,\n",
            " 'Loss/localization_loss': 0.18549311,\n",
            " 'Loss/regularization_loss': 0.15519567,\n",
            " 'Loss/total_loss': 0.49378026,\n",
            " 'learning_rate': 0.08}\n",
            "INFO:tensorflow:Step 1100 per-step time 1.614s\n",
            "I1224 15:57:13.027920 132534240645120 model_lib_v2.py:705] Step 1100 per-step time 1.614s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.34138522,\n",
            " 'Loss/localization_loss': 0.30206263,\n",
            " 'Loss/regularization_loss': 0.15559524,\n",
            " 'Loss/total_loss': 0.79904306,\n",
            " 'learning_rate': 0.07999918}\n",
            "I1224 15:57:13.028361 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.34138522,\n",
            " 'Loss/localization_loss': 0.30206263,\n",
            " 'Loss/regularization_loss': 0.15559524,\n",
            " 'Loss/total_loss': 0.79904306,\n",
            " 'learning_rate': 0.07999918}\n",
            "INFO:tensorflow:Step 1200 per-step time 1.607s\n",
            "I1224 15:59:53.737823 132534240645120 model_lib_v2.py:705] Step 1200 per-step time 1.607s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2747586,\n",
            " 'Loss/localization_loss': 0.19518776,\n",
            " 'Loss/regularization_loss': 0.15573205,\n",
            " 'Loss/total_loss': 0.6256784,\n",
            " 'learning_rate': 0.079996705}\n",
            "I1224 15:59:53.738236 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.2747586,\n",
            " 'Loss/localization_loss': 0.19518776,\n",
            " 'Loss/regularization_loss': 0.15573205,\n",
            " 'Loss/total_loss': 0.6256784,\n",
            " 'learning_rate': 0.079996705}\n",
            "INFO:tensorflow:Step 1300 per-step time 1.572s\n",
            "I1224 16:02:30.970080 132534240645120 model_lib_v2.py:705] Step 1300 per-step time 1.572s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.35254228,\n",
            " 'Loss/localization_loss': 0.38809782,\n",
            " 'Loss/regularization_loss': 0.15552776,\n",
            " 'Loss/total_loss': 0.8961679,\n",
            " 'learning_rate': 0.0799926}\n",
            "I1224 16:02:30.970500 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.35254228,\n",
            " 'Loss/localization_loss': 0.38809782,\n",
            " 'Loss/regularization_loss': 0.15552776,\n",
            " 'Loss/total_loss': 0.8961679,\n",
            " 'learning_rate': 0.0799926}\n",
            "INFO:tensorflow:Step 1400 per-step time 1.572s\n",
            "I1224 16:05:08.136913 132534240645120 model_lib_v2.py:705] Step 1400 per-step time 1.572s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.36217317,\n",
            " 'Loss/localization_loss': 0.2937099,\n",
            " 'Loss/regularization_loss': 0.1554897,\n",
            " 'Loss/total_loss': 0.81137276,\n",
            " 'learning_rate': 0.07998685}\n",
            "I1224 16:05:08.137320 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.36217317,\n",
            " 'Loss/localization_loss': 0.2937099,\n",
            " 'Loss/regularization_loss': 0.1554897,\n",
            " 'Loss/total_loss': 0.81137276,\n",
            " 'learning_rate': 0.07998685}\n",
            "INFO:tensorflow:Step 1500 per-step time 1.604s\n",
            "I1224 16:07:48.576248 132534240645120 model_lib_v2.py:705] Step 1500 per-step time 1.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.24508427,\n",
            " 'Loss/localization_loss': 0.17605764,\n",
            " 'Loss/regularization_loss': 0.15540832,\n",
            " 'Loss/total_loss': 0.57655025,\n",
            " 'learning_rate': 0.07997945}\n",
            "I1224 16:07:48.576650 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.24508427,\n",
            " 'Loss/localization_loss': 0.17605764,\n",
            " 'Loss/regularization_loss': 0.15540832,\n",
            " 'Loss/total_loss': 0.57655025,\n",
            " 'learning_rate': 0.07997945}\n",
            "INFO:tensorflow:Step 1600 per-step time 1.566s\n",
            "I1224 16:10:25.208226 132534240645120 model_lib_v2.py:705] Step 1600 per-step time 1.566s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2351391,\n",
            " 'Loss/localization_loss': 0.31593415,\n",
            " 'Loss/regularization_loss': 0.15509865,\n",
            " 'Loss/total_loss': 0.7061719,\n",
            " 'learning_rate': 0.079970405}\n",
            "I1224 16:10:25.208628 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.2351391,\n",
            " 'Loss/localization_loss': 0.31593415,\n",
            " 'Loss/regularization_loss': 0.15509865,\n",
            " 'Loss/total_loss': 0.7061719,\n",
            " 'learning_rate': 0.079970405}\n",
            "INFO:tensorflow:Step 1700 per-step time 1.591s\n",
            "I1224 16:13:04.272198 132534240645120 model_lib_v2.py:705] Step 1700 per-step time 1.591s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15988207,\n",
            " 'Loss/localization_loss': 0.11974647,\n",
            " 'Loss/regularization_loss': 0.15487432,\n",
            " 'Loss/total_loss': 0.43450287,\n",
            " 'learning_rate': 0.07995972}\n",
            "I1224 16:13:04.272604 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.15988207,\n",
            " 'Loss/localization_loss': 0.11974647,\n",
            " 'Loss/regularization_loss': 0.15487432,\n",
            " 'Loss/total_loss': 0.43450287,\n",
            " 'learning_rate': 0.07995972}\n",
            "INFO:tensorflow:Step 1800 per-step time 1.563s\n",
            "I1224 16:15:40.581027 132534240645120 model_lib_v2.py:705] Step 1800 per-step time 1.563s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17810564,\n",
            " 'Loss/localization_loss': 0.14413235,\n",
            " 'Loss/regularization_loss': 0.15442973,\n",
            " 'Loss/total_loss': 0.4766677,\n",
            " 'learning_rate': 0.0799474}\n",
            "I1224 16:15:40.581430 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.17810564,\n",
            " 'Loss/localization_loss': 0.14413235,\n",
            " 'Loss/regularization_loss': 0.15442973,\n",
            " 'Loss/total_loss': 0.4766677,\n",
            " 'learning_rate': 0.0799474}\n",
            "INFO:tensorflow:Step 1900 per-step time 1.605s\n",
            "I1224 16:18:21.036123 132534240645120 model_lib_v2.py:705] Step 1900 per-step time 1.605s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2970541,\n",
            " 'Loss/localization_loss': 0.14891239,\n",
            " 'Loss/regularization_loss': 0.15407868,\n",
            " 'Loss/total_loss': 0.6000452,\n",
            " 'learning_rate': 0.07993342}\n",
            "I1224 16:18:21.036548 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.2970541,\n",
            " 'Loss/localization_loss': 0.14891239,\n",
            " 'Loss/regularization_loss': 0.15407868,\n",
            " 'Loss/total_loss': 0.6000452,\n",
            " 'learning_rate': 0.07993342}\n",
            "INFO:tensorflow:Step 2000 per-step time 1.572s\n",
            "I1224 16:20:58.208510 132534240645120 model_lib_v2.py:705] Step 2000 per-step time 1.572s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18735278,\n",
            " 'Loss/localization_loss': 0.12876788,\n",
            " 'Loss/regularization_loss': 0.15379614,\n",
            " 'Loss/total_loss': 0.4699168,\n",
            " 'learning_rate': 0.07991781}\n",
            "I1224 16:20:58.208905 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.18735278,\n",
            " 'Loss/localization_loss': 0.12876788,\n",
            " 'Loss/regularization_loss': 0.15379614,\n",
            " 'Loss/total_loss': 0.4699168,\n",
            " 'learning_rate': 0.07991781}\n",
            "INFO:tensorflow:Step 2100 per-step time 1.561s\n",
            "I1224 16:23:34.336277 132534240645120 model_lib_v2.py:705] Step 2100 per-step time 1.561s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.118783295,\n",
            " 'Loss/localization_loss': 0.1429886,\n",
            " 'Loss/regularization_loss': 0.15344277,\n",
            " 'Loss/total_loss': 0.41521466,\n",
            " 'learning_rate': 0.07990056}\n",
            "I1224 16:23:34.336753 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.118783295,\n",
            " 'Loss/localization_loss': 0.1429886,\n",
            " 'Loss/regularization_loss': 0.15344277,\n",
            " 'Loss/total_loss': 0.41521466,\n",
            " 'learning_rate': 0.07990056}\n",
            "INFO:tensorflow:Step 2200 per-step time 1.597s\n",
            "I1224 16:26:14.052818 132534240645120 model_lib_v2.py:705] Step 2200 per-step time 1.597s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13600616,\n",
            " 'Loss/localization_loss': 0.11955482,\n",
            " 'Loss/regularization_loss': 0.15311952,\n",
            " 'Loss/total_loss': 0.4086805,\n",
            " 'learning_rate': 0.07988167}\n",
            "I1224 16:26:14.053348 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.13600616,\n",
            " 'Loss/localization_loss': 0.11955482,\n",
            " 'Loss/regularization_loss': 0.15311952,\n",
            " 'Loss/total_loss': 0.4086805,\n",
            " 'learning_rate': 0.07988167}\n",
            "INFO:tensorflow:Step 2300 per-step time 1.548s\n",
            "I1224 16:28:48.880316 132534240645120 model_lib_v2.py:705] Step 2300 per-step time 1.548s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.2275535,\n",
            " 'Loss/localization_loss': 0.38408488,\n",
            " 'Loss/regularization_loss': 0.15283959,\n",
            " 'Loss/total_loss': 0.76447797,\n",
            " 'learning_rate': 0.07986114}\n",
            "I1224 16:28:48.880790 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.2275535,\n",
            " 'Loss/localization_loss': 0.38408488,\n",
            " 'Loss/regularization_loss': 0.15283959,\n",
            " 'Loss/total_loss': 0.76447797,\n",
            " 'learning_rate': 0.07986114}\n",
            "INFO:tensorflow:Step 2400 per-step time 1.588s\n",
            "I1224 16:31:27.637615 132534240645120 model_lib_v2.py:705] Step 2400 per-step time 1.588s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18995939,\n",
            " 'Loss/localization_loss': 0.2705854,\n",
            " 'Loss/regularization_loss': 0.1526146,\n",
            " 'Loss/total_loss': 0.61315936,\n",
            " 'learning_rate': 0.07983897}\n",
            "I1224 16:31:27.638209 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.18995939,\n",
            " 'Loss/localization_loss': 0.2705854,\n",
            " 'Loss/regularization_loss': 0.1526146,\n",
            " 'Loss/total_loss': 0.61315936,\n",
            " 'learning_rate': 0.07983897}\n",
            "INFO:tensorflow:Step 2500 per-step time 1.562s\n",
            "I1224 16:34:03.808868 132534240645120 model_lib_v2.py:705] Step 2500 per-step time 1.562s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1446525,\n",
            " 'Loss/localization_loss': 0.15860358,\n",
            " 'Loss/regularization_loss': 0.15236188,\n",
            " 'Loss/total_loss': 0.45561796,\n",
            " 'learning_rate': 0.079815164}\n",
            "I1224 16:34:03.809302 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1446525,\n",
            " 'Loss/localization_loss': 0.15860358,\n",
            " 'Loss/regularization_loss': 0.15236188,\n",
            " 'Loss/total_loss': 0.45561796,\n",
            " 'learning_rate': 0.079815164}\n",
            "INFO:tensorflow:Step 2600 per-step time 1.599s\n",
            "I1224 16:36:43.740742 132534240645120 model_lib_v2.py:705] Step 2600 per-step time 1.599s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16217102,\n",
            " 'Loss/localization_loss': 0.14108828,\n",
            " 'Loss/regularization_loss': 0.15194726,\n",
            " 'Loss/total_loss': 0.45520657,\n",
            " 'learning_rate': 0.07978972}\n",
            "I1224 16:36:43.741169 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.16217102,\n",
            " 'Loss/localization_loss': 0.14108828,\n",
            " 'Loss/regularization_loss': 0.15194726,\n",
            " 'Loss/total_loss': 0.45520657,\n",
            " 'learning_rate': 0.07978972}\n",
            "INFO:tensorflow:Step 2700 per-step time 1.565s\n",
            "I1224 16:39:20.231853 132534240645120 model_lib_v2.py:705] Step 2700 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14387539,\n",
            " 'Loss/localization_loss': 0.09224715,\n",
            " 'Loss/regularization_loss': 0.15148565,\n",
            " 'Loss/total_loss': 0.3876082,\n",
            " 'learning_rate': 0.07976264}\n",
            "I1224 16:39:20.232377 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.14387539,\n",
            " 'Loss/localization_loss': 0.09224715,\n",
            " 'Loss/regularization_loss': 0.15148565,\n",
            " 'Loss/total_loss': 0.3876082,\n",
            " 'learning_rate': 0.07976264}\n",
            "INFO:tensorflow:Step 2800 per-step time 1.555s\n",
            "I1224 16:41:55.771118 132534240645120 model_lib_v2.py:705] Step 2800 per-step time 1.555s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15915535,\n",
            " 'Loss/localization_loss': 0.10645869,\n",
            " 'Loss/regularization_loss': 0.15115236,\n",
            " 'Loss/total_loss': 0.4167664,\n",
            " 'learning_rate': 0.07973392}\n",
            "I1224 16:41:55.771539 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.15915535,\n",
            " 'Loss/localization_loss': 0.10645869,\n",
            " 'Loss/regularization_loss': 0.15115236,\n",
            " 'Loss/total_loss': 0.4167664,\n",
            " 'learning_rate': 0.07973392}\n",
            "INFO:tensorflow:Step 2900 per-step time 1.600s\n",
            "I1224 16:44:35.787112 132534240645120 model_lib_v2.py:705] Step 2900 per-step time 1.600s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15536524,\n",
            " 'Loss/localization_loss': 0.17075944,\n",
            " 'Loss/regularization_loss': 0.15106116,\n",
            " 'Loss/total_loss': 0.47718585,\n",
            " 'learning_rate': 0.07970358}\n",
            "I1224 16:44:35.787533 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.15536524,\n",
            " 'Loss/localization_loss': 0.17075944,\n",
            " 'Loss/regularization_loss': 0.15106116,\n",
            " 'Loss/total_loss': 0.47718585,\n",
            " 'learning_rate': 0.07970358}\n",
            "INFO:tensorflow:Step 3000 per-step time 1.567s\n",
            "I1224 16:47:12.526137 132534240645120 model_lib_v2.py:705] Step 3000 per-step time 1.567s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15625764,\n",
            " 'Loss/localization_loss': 0.20394434,\n",
            " 'Loss/regularization_loss': 0.15079105,\n",
            " 'Loss/total_loss': 0.510993,\n",
            " 'learning_rate': 0.0796716}\n",
            "I1224 16:47:12.526588 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.15625764,\n",
            " 'Loss/localization_loss': 0.20394434,\n",
            " 'Loss/regularization_loss': 0.15079105,\n",
            " 'Loss/total_loss': 0.510993,\n",
            " 'learning_rate': 0.0796716}\n",
            "INFO:tensorflow:Step 3100 per-step time 1.608s\n",
            "I1224 16:49:53.314733 132534240645120 model_lib_v2.py:705] Step 3100 per-step time 1.608s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16322643,\n",
            " 'Loss/localization_loss': 0.10712074,\n",
            " 'Loss/regularization_loss': 0.1504154,\n",
            " 'Loss/total_loss': 0.4207626,\n",
            " 'learning_rate': 0.07963799}\n",
            "I1224 16:49:53.315158 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.16322643,\n",
            " 'Loss/localization_loss': 0.10712074,\n",
            " 'Loss/regularization_loss': 0.1504154,\n",
            " 'Loss/total_loss': 0.4207626,\n",
            " 'learning_rate': 0.07963799}\n",
            "INFO:tensorflow:Step 3200 per-step time 1.568s\n",
            "I1224 16:52:30.150846 132534240645120 model_lib_v2.py:705] Step 3200 per-step time 1.568s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14978084,\n",
            " 'Loss/localization_loss': 0.14873038,\n",
            " 'Loss/regularization_loss': 0.15013552,\n",
            " 'Loss/total_loss': 0.44864675,\n",
            " 'learning_rate': 0.07960275}\n",
            "I1224 16:52:30.151270 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.14978084,\n",
            " 'Loss/localization_loss': 0.14873038,\n",
            " 'Loss/regularization_loss': 0.15013552,\n",
            " 'Loss/total_loss': 0.44864675,\n",
            " 'learning_rate': 0.07960275}\n",
            "INFO:tensorflow:Step 3300 per-step time 1.587s\n",
            "I1224 16:55:08.864848 132534240645120 model_lib_v2.py:705] Step 3300 per-step time 1.587s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11936539,\n",
            " 'Loss/localization_loss': 0.18564934,\n",
            " 'Loss/regularization_loss': 0.1496977,\n",
            " 'Loss/total_loss': 0.45471245,\n",
            " 'learning_rate': 0.07956588}\n",
            "I1224 16:55:08.865249 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.11936539,\n",
            " 'Loss/localization_loss': 0.18564934,\n",
            " 'Loss/regularization_loss': 0.1496977,\n",
            " 'Loss/total_loss': 0.45471245,\n",
            " 'learning_rate': 0.07956588}\n",
            "INFO:tensorflow:Step 3400 per-step time 1.551s\n",
            "I1224 16:57:43.924992 132534240645120 model_lib_v2.py:705] Step 3400 per-step time 1.551s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.21427199,\n",
            " 'Loss/localization_loss': 0.15960957,\n",
            " 'Loss/regularization_loss': 0.14922227,\n",
            " 'Loss/total_loss': 0.52310383,\n",
            " 'learning_rate': 0.079527386}\n",
            "I1224 16:57:43.925403 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.21427199,\n",
            " 'Loss/localization_loss': 0.15960957,\n",
            " 'Loss/regularization_loss': 0.14922227,\n",
            " 'Loss/total_loss': 0.52310383,\n",
            " 'learning_rate': 0.079527386}\n",
            "INFO:tensorflow:Step 3500 per-step time 1.600s\n",
            "I1224 17:00:23.915997 132534240645120 model_lib_v2.py:705] Step 3500 per-step time 1.600s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.15070385,\n",
            " 'Loss/localization_loss': 0.16086775,\n",
            " 'Loss/regularization_loss': 0.14883527,\n",
            " 'Loss/total_loss': 0.46040687,\n",
            " 'learning_rate': 0.07948727}\n",
            "I1224 17:00:23.916417 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.15070385,\n",
            " 'Loss/localization_loss': 0.16086775,\n",
            " 'Loss/regularization_loss': 0.14883527,\n",
            " 'Loss/total_loss': 0.46040687,\n",
            " 'learning_rate': 0.07948727}\n",
            "INFO:tensorflow:Step 3600 per-step time 1.554s\n",
            "I1224 17:02:59.347262 132534240645120 model_lib_v2.py:705] Step 3600 per-step time 1.554s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1250506,\n",
            " 'Loss/localization_loss': 0.13218994,\n",
            " 'Loss/regularization_loss': 0.14838831,\n",
            " 'Loss/total_loss': 0.40562886,\n",
            " 'learning_rate': 0.079445526}\n",
            "I1224 17:02:59.347664 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1250506,\n",
            " 'Loss/localization_loss': 0.13218994,\n",
            " 'Loss/regularization_loss': 0.14838831,\n",
            " 'Loss/total_loss': 0.40562886,\n",
            " 'learning_rate': 0.079445526}\n",
            "INFO:tensorflow:Step 3700 per-step time 1.558s\n",
            "I1224 17:05:35.136207 132534240645120 model_lib_v2.py:705] Step 3700 per-step time 1.558s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18129829,\n",
            " 'Loss/localization_loss': 0.117310524,\n",
            " 'Loss/regularization_loss': 0.14791419,\n",
            " 'Loss/total_loss': 0.44652298,\n",
            " 'learning_rate': 0.07940216}\n",
            "I1224 17:05:35.136607 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.18129829,\n",
            " 'Loss/localization_loss': 0.117310524,\n",
            " 'Loss/regularization_loss': 0.14791419,\n",
            " 'Loss/total_loss': 0.44652298,\n",
            " 'learning_rate': 0.07940216}\n",
            "INFO:tensorflow:Step 3800 per-step time 1.584s\n",
            "I1224 17:08:13.495226 132534240645120 model_lib_v2.py:705] Step 3800 per-step time 1.584s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18560196,\n",
            " 'Loss/localization_loss': 0.18473399,\n",
            " 'Loss/regularization_loss': 0.14738598,\n",
            " 'Loss/total_loss': 0.51772195,\n",
            " 'learning_rate': 0.079357184}\n",
            "I1224 17:08:13.495626 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.18560196,\n",
            " 'Loss/localization_loss': 0.18473399,\n",
            " 'Loss/regularization_loss': 0.14738598,\n",
            " 'Loss/total_loss': 0.51772195,\n",
            " 'learning_rate': 0.079357184}\n",
            "INFO:tensorflow:Step 3900 per-step time 1.574s\n",
            "I1224 17:10:50.894300 132534240645120 model_lib_v2.py:705] Step 3900 per-step time 1.574s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11488784,\n",
            " 'Loss/localization_loss': 0.08696386,\n",
            " 'Loss/regularization_loss': 0.14685197,\n",
            " 'Loss/total_loss': 0.34870368,\n",
            " 'learning_rate': 0.07931058}\n",
            "I1224 17:10:50.894692 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.11488784,\n",
            " 'Loss/localization_loss': 0.08696386,\n",
            " 'Loss/regularization_loss': 0.14685197,\n",
            " 'Loss/total_loss': 0.34870368,\n",
            " 'learning_rate': 0.07931058}\n",
            "INFO:tensorflow:Step 4000 per-step time 1.595s\n",
            "I1224 17:13:30.373902 132534240645120 model_lib_v2.py:705] Step 4000 per-step time 1.595s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07353507,\n",
            " 'Loss/localization_loss': 0.06092354,\n",
            " 'Loss/regularization_loss': 0.14626913,\n",
            " 'Loss/total_loss': 0.28072774,\n",
            " 'learning_rate': 0.07926236}\n",
            "I1224 17:13:30.374456 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.07353507,\n",
            " 'Loss/localization_loss': 0.06092354,\n",
            " 'Loss/regularization_loss': 0.14626913,\n",
            " 'Loss/total_loss': 0.28072774,\n",
            " 'learning_rate': 0.07926236}\n",
            "INFO:tensorflow:Step 4100 per-step time 1.665s\n",
            "I1224 17:16:16.865359 132534240645120 model_lib_v2.py:705] Step 4100 per-step time 1.665s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1449451,\n",
            " 'Loss/localization_loss': 0.13719358,\n",
            " 'Loss/regularization_loss': 0.14585619,\n",
            " 'Loss/total_loss': 0.42799485,\n",
            " 'learning_rate': 0.07921253}\n",
            "I1224 17:16:16.865852 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1449451,\n",
            " 'Loss/localization_loss': 0.13719358,\n",
            " 'Loss/regularization_loss': 0.14585619,\n",
            " 'Loss/total_loss': 0.42799485,\n",
            " 'learning_rate': 0.07921253}\n",
            "INFO:tensorflow:Step 4200 per-step time 1.590s\n",
            "I1224 17:18:55.840619 132534240645120 model_lib_v2.py:705] Step 4200 per-step time 1.590s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.088074714,\n",
            " 'Loss/localization_loss': 0.07823714,\n",
            " 'Loss/regularization_loss': 0.14537919,\n",
            " 'Loss/total_loss': 0.31169105,\n",
            " 'learning_rate': 0.07916109}\n",
            "I1224 17:18:55.841167 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.088074714,\n",
            " 'Loss/localization_loss': 0.07823714,\n",
            " 'Loss/regularization_loss': 0.14537919,\n",
            " 'Loss/total_loss': 0.31169105,\n",
            " 'learning_rate': 0.07916109}\n",
            "INFO:tensorflow:Step 4300 per-step time 1.551s\n",
            "I1224 17:21:30.977091 132534240645120 model_lib_v2.py:705] Step 4300 per-step time 1.551s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.14028923,\n",
            " 'Loss/localization_loss': 0.13118471,\n",
            " 'Loss/regularization_loss': 0.14485271,\n",
            " 'Loss/total_loss': 0.41632664,\n",
            " 'learning_rate': 0.07910804}\n",
            "I1224 17:21:30.977587 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.14028923,\n",
            " 'Loss/localization_loss': 0.13118471,\n",
            " 'Loss/regularization_loss': 0.14485271,\n",
            " 'Loss/total_loss': 0.41632664,\n",
            " 'learning_rate': 0.07910804}\n",
            "INFO:tensorflow:Step 4400 per-step time 1.585s\n",
            "I1224 17:24:09.514396 132534240645120 model_lib_v2.py:705] Step 4400 per-step time 1.585s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.123953655,\n",
            " 'Loss/localization_loss': 0.10783042,\n",
            " 'Loss/regularization_loss': 0.14432952,\n",
            " 'Loss/total_loss': 0.3761136,\n",
            " 'learning_rate': 0.07905338}\n",
            "I1224 17:24:09.514926 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.123953655,\n",
            " 'Loss/localization_loss': 0.10783042,\n",
            " 'Loss/regularization_loss': 0.14432952,\n",
            " 'Loss/total_loss': 0.3761136,\n",
            " 'learning_rate': 0.07905338}\n",
            "INFO:tensorflow:Step 4500 per-step time 1.561s\n",
            "I1224 17:26:45.582839 132534240645120 model_lib_v2.py:705] Step 4500 per-step time 1.561s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16388805,\n",
            " 'Loss/localization_loss': 0.12494107,\n",
            " 'Loss/regularization_loss': 0.14386651,\n",
            " 'Loss/total_loss': 0.43269566,\n",
            " 'learning_rate': 0.07899711}\n",
            "I1224 17:26:45.583334 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.16388805,\n",
            " 'Loss/localization_loss': 0.12494107,\n",
            " 'Loss/regularization_loss': 0.14386651,\n",
            " 'Loss/total_loss': 0.43269566,\n",
            " 'learning_rate': 0.07899711}\n",
            "INFO:tensorflow:Step 4600 per-step time 1.612s\n",
            "I1224 17:29:26.821648 132534240645120 model_lib_v2.py:705] Step 4600 per-step time 1.612s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11208392,\n",
            " 'Loss/localization_loss': 0.10642355,\n",
            " 'Loss/regularization_loss': 0.14363097,\n",
            " 'Loss/total_loss': 0.36213842,\n",
            " 'learning_rate': 0.078939244}\n",
            "I1224 17:29:26.822554 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.11208392,\n",
            " 'Loss/localization_loss': 0.10642355,\n",
            " 'Loss/regularization_loss': 0.14363097,\n",
            " 'Loss/total_loss': 0.36213842,\n",
            " 'learning_rate': 0.078939244}\n",
            "INFO:tensorflow:Step 4700 per-step time 1.561s\n",
            "I1224 17:32:02.959253 132534240645120 model_lib_v2.py:705] Step 4700 per-step time 1.561s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12074225,\n",
            " 'Loss/localization_loss': 0.09365447,\n",
            " 'Loss/regularization_loss': 0.14346702,\n",
            " 'Loss/total_loss': 0.35786372,\n",
            " 'learning_rate': 0.07887978}\n",
            "I1224 17:32:02.959652 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12074225,\n",
            " 'Loss/localization_loss': 0.09365447,\n",
            " 'Loss/regularization_loss': 0.14346702,\n",
            " 'Loss/total_loss': 0.35786372,\n",
            " 'learning_rate': 0.07887978}\n",
            "INFO:tensorflow:Step 4800 per-step time 1.553s\n",
            "I1224 17:34:38.223925 132534240645120 model_lib_v2.py:705] Step 4800 per-step time 1.553s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12184638,\n",
            " 'Loss/localization_loss': 0.10771662,\n",
            " 'Loss/regularization_loss': 0.1432808,\n",
            " 'Loss/total_loss': 0.3728438,\n",
            " 'learning_rate': 0.07881871}\n",
            "I1224 17:34:38.224420 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12184638,\n",
            " 'Loss/localization_loss': 0.10771662,\n",
            " 'Loss/regularization_loss': 0.1432808,\n",
            " 'Loss/total_loss': 0.3728438,\n",
            " 'learning_rate': 0.07881871}\n",
            "INFO:tensorflow:Step 4900 per-step time 1.593s\n",
            "I1224 17:37:17.517423 132534240645120 model_lib_v2.py:705] Step 4900 per-step time 1.593s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16055644,\n",
            " 'Loss/localization_loss': 0.1676842,\n",
            " 'Loss/regularization_loss': 0.14322312,\n",
            " 'Loss/total_loss': 0.47146374,\n",
            " 'learning_rate': 0.07875605}\n",
            "I1224 17:37:17.517899 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.16055644,\n",
            " 'Loss/localization_loss': 0.1676842,\n",
            " 'Loss/regularization_loss': 0.14322312,\n",
            " 'Loss/total_loss': 0.47146374,\n",
            " 'learning_rate': 0.07875605}\n",
            "INFO:tensorflow:Step 5000 per-step time 1.570s\n",
            "I1224 17:39:54.517689 132534240645120 model_lib_v2.py:705] Step 5000 per-step time 1.570s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16224065,\n",
            " 'Loss/localization_loss': 0.10779041,\n",
            " 'Loss/regularization_loss': 0.14284152,\n",
            " 'Loss/total_loss': 0.41287258,\n",
            " 'learning_rate': 0.078691795}\n",
            "I1224 17:39:54.518106 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.16224065,\n",
            " 'Loss/localization_loss': 0.10779041,\n",
            " 'Loss/regularization_loss': 0.14284152,\n",
            " 'Loss/total_loss': 0.41287258,\n",
            " 'learning_rate': 0.078691795}\n",
            "INFO:tensorflow:Step 5100 per-step time 1.587s\n",
            "I1224 17:42:33.219453 132534240645120 model_lib_v2.py:705] Step 5100 per-step time 1.587s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10499353,\n",
            " 'Loss/localization_loss': 0.065973215,\n",
            " 'Loss/regularization_loss': 0.14248103,\n",
            " 'Loss/total_loss': 0.31344777,\n",
            " 'learning_rate': 0.07862595}\n",
            "I1224 17:42:33.219950 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.10499353,\n",
            " 'Loss/localization_loss': 0.065973215,\n",
            " 'Loss/regularization_loss': 0.14248103,\n",
            " 'Loss/total_loss': 0.31344777,\n",
            " 'learning_rate': 0.07862595}\n",
            "INFO:tensorflow:Step 5200 per-step time 1.571s\n",
            "I1224 17:45:10.330124 132534240645120 model_lib_v2.py:705] Step 5200 per-step time 1.571s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.19463004,\n",
            " 'Loss/localization_loss': 0.08521304,\n",
            " 'Loss/regularization_loss': 0.14200325,\n",
            " 'Loss/total_loss': 0.42184633,\n",
            " 'learning_rate': 0.07855851}\n",
            "I1224 17:45:10.330622 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.19463004,\n",
            " 'Loss/localization_loss': 0.08521304,\n",
            " 'Loss/regularization_loss': 0.14200325,\n",
            " 'Loss/total_loss': 0.42184633,\n",
            " 'learning_rate': 0.07855851}\n",
            "INFO:tensorflow:Step 5300 per-step time 1.577s\n",
            "I1224 17:47:48.044876 132534240645120 model_lib_v2.py:705] Step 5300 per-step time 1.577s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08789147,\n",
            " 'Loss/localization_loss': 0.06749635,\n",
            " 'Loss/regularization_loss': 0.14160864,\n",
            " 'Loss/total_loss': 0.29699647,\n",
            " 'learning_rate': 0.07848949}\n",
            "I1224 17:47:48.045398 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.08789147,\n",
            " 'Loss/localization_loss': 0.06749635,\n",
            " 'Loss/regularization_loss': 0.14160864,\n",
            " 'Loss/total_loss': 0.29699647,\n",
            " 'learning_rate': 0.07848949}\n",
            "INFO:tensorflow:Step 5400 per-step time 1.565s\n",
            "I1224 17:50:24.522179 132534240645120 model_lib_v2.py:705] Step 5400 per-step time 1.565s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17958891,\n",
            " 'Loss/localization_loss': 0.12807947,\n",
            " 'Loss/regularization_loss': 0.14185779,\n",
            " 'Loss/total_loss': 0.4495262,\n",
            " 'learning_rate': 0.078418896}\n",
            "I1224 17:50:24.522897 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.17958891,\n",
            " 'Loss/localization_loss': 0.12807947,\n",
            " 'Loss/regularization_loss': 0.14185779,\n",
            " 'Loss/total_loss': 0.4495262,\n",
            " 'learning_rate': 0.078418896}\n",
            "INFO:tensorflow:Step 5500 per-step time 1.600s\n",
            "I1224 17:53:04.491109 132534240645120 model_lib_v2.py:705] Step 5500 per-step time 1.600s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13720079,\n",
            " 'Loss/localization_loss': 0.04461446,\n",
            " 'Loss/regularization_loss': 0.14147864,\n",
            " 'Loss/total_loss': 0.3232939,\n",
            " 'learning_rate': 0.078346714}\n",
            "I1224 17:53:04.491524 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.13720079,\n",
            " 'Loss/localization_loss': 0.04461446,\n",
            " 'Loss/regularization_loss': 0.14147864,\n",
            " 'Loss/total_loss': 0.3232939,\n",
            " 'learning_rate': 0.078346714}\n",
            "INFO:tensorflow:Step 5600 per-step time 1.576s\n",
            "I1224 17:55:42.053648 132534240645120 model_lib_v2.py:705] Step 5600 per-step time 1.576s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.18582766,\n",
            " 'Loss/localization_loss': 0.16487052,\n",
            " 'Loss/regularization_loss': 0.14103927,\n",
            " 'Loss/total_loss': 0.49173743,\n",
            " 'learning_rate': 0.07827295}\n",
            "I1224 17:55:42.054107 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.18582766,\n",
            " 'Loss/localization_loss': 0.16487052,\n",
            " 'Loss/regularization_loss': 0.14103927,\n",
            " 'Loss/total_loss': 0.49173743,\n",
            " 'learning_rate': 0.07827295}\n",
            "INFO:tensorflow:Step 5700 per-step time 1.603s\n",
            "I1224 17:58:22.303294 132534240645120 model_lib_v2.py:705] Step 5700 per-step time 1.603s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08415365,\n",
            " 'Loss/localization_loss': 0.05965903,\n",
            " 'Loss/regularization_loss': 0.1405337,\n",
            " 'Loss/total_loss': 0.2843464,\n",
            " 'learning_rate': 0.07819763}\n",
            "I1224 17:58:22.303718 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.08415365,\n",
            " 'Loss/localization_loss': 0.05965903,\n",
            " 'Loss/regularization_loss': 0.1405337,\n",
            " 'Loss/total_loss': 0.2843464,\n",
            " 'learning_rate': 0.07819763}\n",
            "INFO:tensorflow:Step 5800 per-step time 1.599s\n",
            "I1224 18:01:02.166622 132534240645120 model_lib_v2.py:705] Step 5800 per-step time 1.599s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11122191,\n",
            " 'Loss/localization_loss': 0.03212797,\n",
            " 'Loss/regularization_loss': 0.13999212,\n",
            " 'Loss/total_loss': 0.283342,\n",
            " 'learning_rate': 0.07812072}\n",
            "I1224 18:01:02.167123 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.11122191,\n",
            " 'Loss/localization_loss': 0.03212797,\n",
            " 'Loss/regularization_loss': 0.13999212,\n",
            " 'Loss/total_loss': 0.283342,\n",
            " 'learning_rate': 0.07812072}\n",
            "INFO:tensorflow:Step 5900 per-step time 1.622s\n",
            "I1224 18:03:44.403676 132534240645120 model_lib_v2.py:705] Step 5900 per-step time 1.622s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0627338,\n",
            " 'Loss/localization_loss': 0.05709395,\n",
            " 'Loss/regularization_loss': 0.1394735,\n",
            " 'Loss/total_loss': 0.25930125,\n",
            " 'learning_rate': 0.078042254}\n",
            "I1224 18:03:44.404191 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.0627338,\n",
            " 'Loss/localization_loss': 0.05709395,\n",
            " 'Loss/regularization_loss': 0.1394735,\n",
            " 'Loss/total_loss': 0.25930125,\n",
            " 'learning_rate': 0.078042254}\n",
            "INFO:tensorflow:Step 6000 per-step time 1.594s\n",
            "I1224 18:06:23.763384 132534240645120 model_lib_v2.py:705] Step 6000 per-step time 1.594s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10342966,\n",
            " 'Loss/localization_loss': 0.069431245,\n",
            " 'Loss/regularization_loss': 0.13893908,\n",
            " 'Loss/total_loss': 0.3118,\n",
            " 'learning_rate': 0.07796223}\n",
            "I1224 18:06:23.763955 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.10342966,\n",
            " 'Loss/localization_loss': 0.069431245,\n",
            " 'Loss/regularization_loss': 0.13893908,\n",
            " 'Loss/total_loss': 0.3118,\n",
            " 'learning_rate': 0.07796223}\n",
            "INFO:tensorflow:Step 6100 per-step time 1.604s\n",
            "I1224 18:09:04.198400 132534240645120 model_lib_v2.py:705] Step 6100 per-step time 1.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.117859624,\n",
            " 'Loss/localization_loss': 0.11314523,\n",
            " 'Loss/regularization_loss': 0.1385338,\n",
            " 'Loss/total_loss': 0.36953866,\n",
            " 'learning_rate': 0.077880636}\n",
            "I1224 18:09:04.198827 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.117859624,\n",
            " 'Loss/localization_loss': 0.11314523,\n",
            " 'Loss/regularization_loss': 0.1385338,\n",
            " 'Loss/total_loss': 0.36953866,\n",
            " 'learning_rate': 0.077880636}\n",
            "INFO:tensorflow:Step 6200 per-step time 1.556s\n",
            "I1224 18:11:39.792384 132534240645120 model_lib_v2.py:705] Step 6200 per-step time 1.556s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12744898,\n",
            " 'Loss/localization_loss': 0.08973191,\n",
            " 'Loss/regularization_loss': 0.13804191,\n",
            " 'Loss/total_loss': 0.3552228,\n",
            " 'learning_rate': 0.07779749}\n",
            "I1224 18:11:39.792862 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12744898,\n",
            " 'Loss/localization_loss': 0.08973191,\n",
            " 'Loss/regularization_loss': 0.13804191,\n",
            " 'Loss/total_loss': 0.3552228,\n",
            " 'learning_rate': 0.07779749}\n",
            "INFO:tensorflow:Step 6300 per-step time 1.570s\n",
            "I1224 18:14:16.832865 132534240645120 model_lib_v2.py:705] Step 6300 per-step time 1.570s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.08560157,\n",
            " 'Loss/localization_loss': 0.052844968,\n",
            " 'Loss/regularization_loss': 0.13747081,\n",
            " 'Loss/total_loss': 0.27591735,\n",
            " 'learning_rate': 0.07771279}\n",
            "I1224 18:14:16.833428 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.08560157,\n",
            " 'Loss/localization_loss': 0.052844968,\n",
            " 'Loss/regularization_loss': 0.13747081,\n",
            " 'Loss/total_loss': 0.27591735,\n",
            " 'learning_rate': 0.07771279}\n",
            "INFO:tensorflow:Step 6400 per-step time 1.546s\n",
            "I1224 18:16:51.407478 132534240645120 model_lib_v2.py:705] Step 6400 per-step time 1.546s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11208798,\n",
            " 'Loss/localization_loss': 0.09964096,\n",
            " 'Loss/regularization_loss': 0.13691567,\n",
            " 'Loss/total_loss': 0.3486446,\n",
            " 'learning_rate': 0.077626534}\n",
            "I1224 18:16:51.407865 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.11208798,\n",
            " 'Loss/localization_loss': 0.09964096,\n",
            " 'Loss/regularization_loss': 0.13691567,\n",
            " 'Loss/total_loss': 0.3486446,\n",
            " 'learning_rate': 0.077626534}\n",
            "INFO:tensorflow:Step 6500 per-step time 1.598s\n",
            "I1224 18:19:31.190152 132534240645120 model_lib_v2.py:705] Step 6500 per-step time 1.598s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0812191,\n",
            " 'Loss/localization_loss': 0.047266413,\n",
            " 'Loss/regularization_loss': 0.13636823,\n",
            " 'Loss/total_loss': 0.26485375,\n",
            " 'learning_rate': 0.077538736}\n",
            "I1224 18:19:31.190725 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.0812191,\n",
            " 'Loss/localization_loss': 0.047266413,\n",
            " 'Loss/regularization_loss': 0.13636823,\n",
            " 'Loss/total_loss': 0.26485375,\n",
            " 'learning_rate': 0.077538736}\n",
            "INFO:tensorflow:Step 6600 per-step time 1.553s\n",
            "I1224 18:22:06.529696 132534240645120 model_lib_v2.py:705] Step 6600 per-step time 1.553s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12500669,\n",
            " 'Loss/localization_loss': 0.08615757,\n",
            " 'Loss/regularization_loss': 0.13583264,\n",
            " 'Loss/total_loss': 0.3469969,\n",
            " 'learning_rate': 0.07744939}\n",
            "I1224 18:22:06.530089 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12500669,\n",
            " 'Loss/localization_loss': 0.08615757,\n",
            " 'Loss/regularization_loss': 0.13583264,\n",
            " 'Loss/total_loss': 0.3469969,\n",
            " 'learning_rate': 0.07744939}\n",
            "INFO:tensorflow:Step 6700 per-step time 1.566s\n",
            "I1224 18:24:43.134445 132534240645120 model_lib_v2.py:705] Step 6700 per-step time 1.566s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.16028355,\n",
            " 'Loss/localization_loss': 0.108055726,\n",
            " 'Loss/regularization_loss': 0.13541916,\n",
            " 'Loss/total_loss': 0.40375844,\n",
            " 'learning_rate': 0.077358514}\n",
            "I1224 18:24:43.134838 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.16028355,\n",
            " 'Loss/localization_loss': 0.108055726,\n",
            " 'Loss/regularization_loss': 0.13541916,\n",
            " 'Loss/total_loss': 0.40375844,\n",
            " 'learning_rate': 0.077358514}\n",
            "INFO:tensorflow:Step 6800 per-step time 1.544s\n",
            "I1224 18:27:17.579949 132534240645120 model_lib_v2.py:705] Step 6800 per-step time 1.544s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.102791466,\n",
            " 'Loss/localization_loss': 0.07774898,\n",
            " 'Loss/regularization_loss': 0.13490997,\n",
            " 'Loss/total_loss': 0.3154504,\n",
            " 'learning_rate': 0.0772661}\n",
            "I1224 18:27:17.580364 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.102791466,\n",
            " 'Loss/localization_loss': 0.07774898,\n",
            " 'Loss/regularization_loss': 0.13490997,\n",
            " 'Loss/total_loss': 0.3154504,\n",
            " 'learning_rate': 0.0772661}\n",
            "INFO:tensorflow:Step 6900 per-step time 1.596s\n",
            "I1224 18:29:57.165645 132534240645120 model_lib_v2.py:705] Step 6900 per-step time 1.596s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09969532,\n",
            " 'Loss/localization_loss': 0.084790766,\n",
            " 'Loss/regularization_loss': 0.13438652,\n",
            " 'Loss/total_loss': 0.3188726,\n",
            " 'learning_rate': 0.077172145}\n",
            "I1224 18:29:57.166047 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.09969532,\n",
            " 'Loss/localization_loss': 0.084790766,\n",
            " 'Loss/regularization_loss': 0.13438652,\n",
            " 'Loss/total_loss': 0.3188726,\n",
            " 'learning_rate': 0.077172145}\n",
            "INFO:tensorflow:Step 7000 per-step time 1.557s\n",
            "I1224 18:32:32.837568 132534240645120 model_lib_v2.py:705] Step 7000 per-step time 1.557s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1419928,\n",
            " 'Loss/localization_loss': 0.11893268,\n",
            " 'Loss/regularization_loss': 0.13389815,\n",
            " 'Loss/total_loss': 0.39482364,\n",
            " 'learning_rate': 0.07707667}\n",
            "I1224 18:32:32.837989 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1419928,\n",
            " 'Loss/localization_loss': 0.11893268,\n",
            " 'Loss/regularization_loss': 0.13389815,\n",
            " 'Loss/total_loss': 0.39482364,\n",
            " 'learning_rate': 0.07707667}\n",
            "INFO:tensorflow:Step 7100 per-step time 1.579s\n",
            "I1224 18:35:10.757124 132534240645120 model_lib_v2.py:705] Step 7100 per-step time 1.579s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17470697,\n",
            " 'Loss/localization_loss': 0.116709515,\n",
            " 'Loss/regularization_loss': 0.13345012,\n",
            " 'Loss/total_loss': 0.42486662,\n",
            " 'learning_rate': 0.07697967}\n",
            "I1224 18:35:10.757702 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.17470697,\n",
            " 'Loss/localization_loss': 0.116709515,\n",
            " 'Loss/regularization_loss': 0.13345012,\n",
            " 'Loss/total_loss': 0.42486662,\n",
            " 'learning_rate': 0.07697967}\n",
            "INFO:tensorflow:Step 7200 per-step time 1.544s\n",
            "I1224 18:37:45.123180 132534240645120 model_lib_v2.py:705] Step 7200 per-step time 1.544s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0882929,\n",
            " 'Loss/localization_loss': 0.053530406,\n",
            " 'Loss/regularization_loss': 0.13328019,\n",
            " 'Loss/total_loss': 0.2751035,\n",
            " 'learning_rate': 0.07688115}\n",
            "I1224 18:37:45.123569 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.0882929,\n",
            " 'Loss/localization_loss': 0.053530406,\n",
            " 'Loss/regularization_loss': 0.13328019,\n",
            " 'Loss/total_loss': 0.2751035,\n",
            " 'learning_rate': 0.07688115}\n",
            "INFO:tensorflow:Step 7300 per-step time 1.574s\n",
            "I1224 18:40:22.560422 132534240645120 model_lib_v2.py:705] Step 7300 per-step time 1.574s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.087629415,\n",
            " 'Loss/localization_loss': 0.061806083,\n",
            " 'Loss/regularization_loss': 0.13292815,\n",
            " 'Loss/total_loss': 0.28236365,\n",
            " 'learning_rate': 0.07678111}\n",
            "I1224 18:40:22.560831 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.087629415,\n",
            " 'Loss/localization_loss': 0.061806083,\n",
            " 'Loss/regularization_loss': 0.13292815,\n",
            " 'Loss/total_loss': 0.28236365,\n",
            " 'learning_rate': 0.07678111}\n",
            "INFO:tensorflow:Step 7400 per-step time 1.551s\n",
            "I1224 18:42:57.659463 132534240645120 model_lib_v2.py:705] Step 7400 per-step time 1.551s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12635174,\n",
            " 'Loss/localization_loss': 0.14929162,\n",
            " 'Loss/regularization_loss': 0.13264833,\n",
            " 'Loss/total_loss': 0.4082917,\n",
            " 'learning_rate': 0.076679565}\n",
            "I1224 18:42:57.659909 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12635174,\n",
            " 'Loss/localization_loss': 0.14929162,\n",
            " 'Loss/regularization_loss': 0.13264833,\n",
            " 'Loss/total_loss': 0.4082917,\n",
            " 'learning_rate': 0.076679565}\n",
            "INFO:tensorflow:Step 7500 per-step time 1.588s\n",
            "I1224 18:45:36.410037 132534240645120 model_lib_v2.py:705] Step 7500 per-step time 1.588s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.104160294,\n",
            " 'Loss/localization_loss': 0.092973515,\n",
            " 'Loss/regularization_loss': 0.13232577,\n",
            " 'Loss/total_loss': 0.32945958,\n",
            " 'learning_rate': 0.0765765}\n",
            "I1224 18:45:36.410456 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.104160294,\n",
            " 'Loss/localization_loss': 0.092973515,\n",
            " 'Loss/regularization_loss': 0.13232577,\n",
            " 'Loss/total_loss': 0.32945958,\n",
            " 'learning_rate': 0.0765765}\n",
            "INFO:tensorflow:Step 7600 per-step time 1.604s\n",
            "I1224 18:48:16.845204 132534240645120 model_lib_v2.py:705] Step 7600 per-step time 1.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1307335,\n",
            " 'Loss/localization_loss': 0.056604136,\n",
            " 'Loss/regularization_loss': 0.13191906,\n",
            " 'Loss/total_loss': 0.3192567,\n",
            " 'learning_rate': 0.07647194}\n",
            "I1224 18:48:16.845618 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1307335,\n",
            " 'Loss/localization_loss': 0.056604136,\n",
            " 'Loss/regularization_loss': 0.13191906,\n",
            " 'Loss/total_loss': 0.3192567,\n",
            " 'learning_rate': 0.07647194}\n",
            "INFO:tensorflow:Step 7700 per-step time 1.604s\n",
            "I1224 18:50:57.272880 132534240645120 model_lib_v2.py:705] Step 7700 per-step time 1.604s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1637244,\n",
            " 'Loss/localization_loss': 0.21154109,\n",
            " 'Loss/regularization_loss': 0.13155957,\n",
            " 'Loss/total_loss': 0.5068251,\n",
            " 'learning_rate': 0.07636588}\n",
            "I1224 18:50:57.273289 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1637244,\n",
            " 'Loss/localization_loss': 0.21154109,\n",
            " 'Loss/regularization_loss': 0.13155957,\n",
            " 'Loss/total_loss': 0.5068251,\n",
            " 'learning_rate': 0.07636588}\n",
            "INFO:tensorflow:Step 7800 per-step time 1.610s\n",
            "I1224 18:53:38.325620 132534240645120 model_lib_v2.py:705] Step 7800 per-step time 1.610s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1187793,\n",
            " 'Loss/localization_loss': 0.1028535,\n",
            " 'Loss/regularization_loss': 0.13109943,\n",
            " 'Loss/total_loss': 0.35273224,\n",
            " 'learning_rate': 0.07625833}\n",
            "I1224 18:53:38.327605 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1187793,\n",
            " 'Loss/localization_loss': 0.1028535,\n",
            " 'Loss/regularization_loss': 0.13109943,\n",
            " 'Loss/total_loss': 0.35273224,\n",
            " 'learning_rate': 0.07625833}\n",
            "INFO:tensorflow:Step 7900 per-step time 1.597s\n",
            "I1224 18:56:18.013723 132534240645120 model_lib_v2.py:705] Step 7900 per-step time 1.597s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.07569507,\n",
            " 'Loss/localization_loss': 0.054804474,\n",
            " 'Loss/regularization_loss': 0.13074124,\n",
            " 'Loss/total_loss': 0.26124078,\n",
            " 'learning_rate': 0.07614928}\n",
            "I1224 18:56:18.014140 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.07569507,\n",
            " 'Loss/localization_loss': 0.054804474,\n",
            " 'Loss/regularization_loss': 0.13074124,\n",
            " 'Loss/total_loss': 0.26124078,\n",
            " 'learning_rate': 0.07614928}\n",
            "INFO:tensorflow:Step 8000 per-step time 1.561s\n",
            "I1224 18:58:54.106336 132534240645120 model_lib_v2.py:705] Step 8000 per-step time 1.561s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.27204812,\n",
            " 'Loss/localization_loss': 0.10853008,\n",
            " 'Loss/regularization_loss': 0.13032809,\n",
            " 'Loss/total_loss': 0.5109063,\n",
            " 'learning_rate': 0.07603875}\n",
            "I1224 18:58:54.106731 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.27204812,\n",
            " 'Loss/localization_loss': 0.10853008,\n",
            " 'Loss/regularization_loss': 0.13032809,\n",
            " 'Loss/total_loss': 0.5109063,\n",
            " 'learning_rate': 0.07603875}\n",
            "INFO:tensorflow:Step 8100 per-step time 1.606s\n",
            "I1224 19:01:34.688872 132534240645120 model_lib_v2.py:705] Step 8100 per-step time 1.606s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1093976,\n",
            " 'Loss/localization_loss': 0.11258652,\n",
            " 'Loss/regularization_loss': 0.12994976,\n",
            " 'Loss/total_loss': 0.35193387,\n",
            " 'learning_rate': 0.07592674}\n",
            "I1224 19:01:34.689294 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1093976,\n",
            " 'Loss/localization_loss': 0.11258652,\n",
            " 'Loss/regularization_loss': 0.12994976,\n",
            " 'Loss/total_loss': 0.35193387,\n",
            " 'learning_rate': 0.07592674}\n",
            "INFO:tensorflow:Step 8200 per-step time 1.551s\n",
            "I1224 19:04:09.779059 132534240645120 model_lib_v2.py:705] Step 8200 per-step time 1.551s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12428782,\n",
            " 'Loss/localization_loss': 0.07527422,\n",
            " 'Loss/regularization_loss': 0.12947497,\n",
            " 'Loss/total_loss': 0.329037,\n",
            " 'learning_rate': 0.075813256}\n",
            "I1224 19:04:09.779471 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12428782,\n",
            " 'Loss/localization_loss': 0.07527422,\n",
            " 'Loss/regularization_loss': 0.12947497,\n",
            " 'Loss/total_loss': 0.329037,\n",
            " 'learning_rate': 0.075813256}\n",
            "INFO:tensorflow:Step 8300 per-step time 1.591s\n",
            "I1224 19:06:48.852900 132534240645120 model_lib_v2.py:705] Step 8300 per-step time 1.591s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10113119,\n",
            " 'Loss/localization_loss': 0.055071477,\n",
            " 'Loss/regularization_loss': 0.12907381,\n",
            " 'Loss/total_loss': 0.28527647,\n",
            " 'learning_rate': 0.07569829}\n",
            "I1224 19:06:48.853302 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.10113119,\n",
            " 'Loss/localization_loss': 0.055071477,\n",
            " 'Loss/regularization_loss': 0.12907381,\n",
            " 'Loss/total_loss': 0.28527647,\n",
            " 'learning_rate': 0.07569829}\n",
            "INFO:tensorflow:Step 8400 per-step time 1.578s\n",
            "I1224 19:09:26.670177 132534240645120 model_lib_v2.py:705] Step 8400 per-step time 1.578s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.079626165,\n",
            " 'Loss/localization_loss': 0.04858348,\n",
            " 'Loss/regularization_loss': 0.12859641,\n",
            " 'Loss/total_loss': 0.25680605,\n",
            " 'learning_rate': 0.07558186}\n",
            "I1224 19:09:26.670614 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.079626165,\n",
            " 'Loss/localization_loss': 0.04858348,\n",
            " 'Loss/regularization_loss': 0.12859641,\n",
            " 'Loss/total_loss': 0.25680605,\n",
            " 'learning_rate': 0.07558186}\n",
            "INFO:tensorflow:Step 8500 per-step time 1.611s\n",
            "I1224 19:12:07.779311 132534240645120 model_lib_v2.py:705] Step 8500 per-step time 1.611s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09679698,\n",
            " 'Loss/localization_loss': 0.057936706,\n",
            " 'Loss/regularization_loss': 0.128202,\n",
            " 'Loss/total_loss': 0.2829357,\n",
            " 'learning_rate': 0.07546397}\n",
            "I1224 19:12:07.779802 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.09679698,\n",
            " 'Loss/localization_loss': 0.057936706,\n",
            " 'Loss/regularization_loss': 0.128202,\n",
            " 'Loss/total_loss': 0.2829357,\n",
            " 'learning_rate': 0.07546397}\n",
            "INFO:tensorflow:Step 8600 per-step time 1.564s\n",
            "I1224 19:14:44.186385 132534240645120 model_lib_v2.py:705] Step 8600 per-step time 1.564s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1385124,\n",
            " 'Loss/localization_loss': 0.1521454,\n",
            " 'Loss/regularization_loss': 0.12778457,\n",
            " 'Loss/total_loss': 0.41844237,\n",
            " 'learning_rate': 0.075344615}\n",
            "I1224 19:14:44.186877 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1385124,\n",
            " 'Loss/localization_loss': 0.1521454,\n",
            " 'Loss/regularization_loss': 0.12778457,\n",
            " 'Loss/total_loss': 0.41844237,\n",
            " 'learning_rate': 0.075344615}\n",
            "INFO:tensorflow:Step 8700 per-step time 1.589s\n",
            "I1224 19:17:23.034083 132534240645120 model_lib_v2.py:705] Step 8700 per-step time 1.589s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12483615,\n",
            " 'Loss/localization_loss': 0.0816325,\n",
            " 'Loss/regularization_loss': 0.12731741,\n",
            " 'Loss/total_loss': 0.33378607,\n",
            " 'learning_rate': 0.07522382}\n",
            "I1224 19:17:23.034492 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12483615,\n",
            " 'Loss/localization_loss': 0.0816325,\n",
            " 'Loss/regularization_loss': 0.12731741,\n",
            " 'Loss/total_loss': 0.33378607,\n",
            " 'learning_rate': 0.07522382}\n",
            "INFO:tensorflow:Step 8800 per-step time 1.556s\n",
            "I1224 19:19:58.652944 132534240645120 model_lib_v2.py:705] Step 8800 per-step time 1.556s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10217026,\n",
            " 'Loss/localization_loss': 0.09118983,\n",
            " 'Loss/regularization_loss': 0.12684904,\n",
            " 'Loss/total_loss': 0.32020915,\n",
            " 'learning_rate': 0.07510157}\n",
            "I1224 19:19:58.653366 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.10217026,\n",
            " 'Loss/localization_loss': 0.09118983,\n",
            " 'Loss/regularization_loss': 0.12684904,\n",
            " 'Loss/total_loss': 0.32020915,\n",
            " 'learning_rate': 0.07510157}\n",
            "INFO:tensorflow:Step 8900 per-step time 1.597s\n",
            "I1224 19:22:38.345610 132534240645120 model_lib_v2.py:705] Step 8900 per-step time 1.597s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.13873143,\n",
            " 'Loss/localization_loss': 0.07090249,\n",
            " 'Loss/regularization_loss': 0.12642448,\n",
            " 'Loss/total_loss': 0.33605838,\n",
            " 'learning_rate': 0.074977875}\n",
            "I1224 19:22:38.346131 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.13873143,\n",
            " 'Loss/localization_loss': 0.07090249,\n",
            " 'Loss/regularization_loss': 0.12642448,\n",
            " 'Loss/total_loss': 0.33605838,\n",
            " 'learning_rate': 0.074977875}\n",
            "INFO:tensorflow:Step 9000 per-step time 1.585s\n",
            "I1224 19:25:16.889455 132534240645120 model_lib_v2.py:705] Step 9000 per-step time 1.585s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.093120836,\n",
            " 'Loss/localization_loss': 0.058265228,\n",
            " 'Loss/regularization_loss': 0.12623885,\n",
            " 'Loss/total_loss': 0.27762493,\n",
            " 'learning_rate': 0.07485275}\n",
            "I1224 19:25:16.889848 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.093120836,\n",
            " 'Loss/localization_loss': 0.058265228,\n",
            " 'Loss/regularization_loss': 0.12623885,\n",
            " 'Loss/total_loss': 0.27762493,\n",
            " 'learning_rate': 0.07485275}\n",
            "INFO:tensorflow:Step 9100 per-step time 1.571s\n",
            "I1224 19:27:54.032406 132534240645120 model_lib_v2.py:705] Step 9100 per-step time 1.571s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.0885631,\n",
            " 'Loss/localization_loss': 0.0809949,\n",
            " 'Loss/regularization_loss': 0.12582229,\n",
            " 'Loss/total_loss': 0.2953803,\n",
            " 'learning_rate': 0.07472619}\n",
            "I1224 19:27:54.032833 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.0885631,\n",
            " 'Loss/localization_loss': 0.0809949,\n",
            " 'Loss/regularization_loss': 0.12582229,\n",
            " 'Loss/total_loss': 0.2953803,\n",
            " 'learning_rate': 0.07472619}\n",
            "INFO:tensorflow:Step 9200 per-step time 1.597s\n",
            "I1224 19:30:33.719745 132534240645120 model_lib_v2.py:705] Step 9200 per-step time 1.597s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.17085703,\n",
            " 'Loss/localization_loss': 0.14341511,\n",
            " 'Loss/regularization_loss': 0.1253843,\n",
            " 'Loss/total_loss': 0.43965644,\n",
            " 'learning_rate': 0.07459819}\n",
            "I1224 19:30:33.720286 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.17085703,\n",
            " 'Loss/localization_loss': 0.14341511,\n",
            " 'Loss/regularization_loss': 0.1253843,\n",
            " 'Loss/total_loss': 0.43965644,\n",
            " 'learning_rate': 0.07459819}\n",
            "INFO:tensorflow:Step 9300 per-step time 1.561s\n",
            "I1224 19:33:09.850044 132534240645120 model_lib_v2.py:705] Step 9300 per-step time 1.561s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12088911,\n",
            " 'Loss/localization_loss': 0.08024498,\n",
            " 'Loss/regularization_loss': 0.12509319,\n",
            " 'Loss/total_loss': 0.32622728,\n",
            " 'learning_rate': 0.074468784}\n",
            "I1224 19:33:09.850542 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12088911,\n",
            " 'Loss/localization_loss': 0.08024498,\n",
            " 'Loss/regularization_loss': 0.12509319,\n",
            " 'Loss/total_loss': 0.32622728,\n",
            " 'learning_rate': 0.074468784}\n",
            "INFO:tensorflow:Step 9400 per-step time 1.592s\n",
            "I1224 19:35:49.031629 132534240645120 model_lib_v2.py:705] Step 9400 per-step time 1.592s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.12210648,\n",
            " 'Loss/localization_loss': 0.08896836,\n",
            " 'Loss/regularization_loss': 0.12471644,\n",
            " 'Loss/total_loss': 0.3357913,\n",
            " 'learning_rate': 0.074337944}\n",
            "I1224 19:35:49.032130 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.12210648,\n",
            " 'Loss/localization_loss': 0.08896836,\n",
            " 'Loss/regularization_loss': 0.12471644,\n",
            " 'Loss/total_loss': 0.3357913,\n",
            " 'learning_rate': 0.074337944}\n",
            "INFO:tensorflow:Step 9500 per-step time 1.543s\n",
            "I1224 19:38:23.359889 132534240645120 model_lib_v2.py:705] Step 9500 per-step time 1.543s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.09741934,\n",
            " 'Loss/localization_loss': 0.045676377,\n",
            " 'Loss/regularization_loss': 0.12437738,\n",
            " 'Loss/total_loss': 0.2674731,\n",
            " 'learning_rate': 0.074205704}\n",
            "I1224 19:38:23.360383 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.09741934,\n",
            " 'Loss/localization_loss': 0.045676377,\n",
            " 'Loss/regularization_loss': 0.12437738,\n",
            " 'Loss/total_loss': 0.2674731,\n",
            " 'learning_rate': 0.074205704}\n",
            "INFO:tensorflow:Step 9600 per-step time 1.574s\n",
            "I1224 19:41:00.765089 132534240645120 model_lib_v2.py:705] Step 9600 per-step time 1.574s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.1467912,\n",
            " 'Loss/localization_loss': 0.1008444,\n",
            " 'Loss/regularization_loss': 0.12395141,\n",
            " 'Loss/total_loss': 0.37158704,\n",
            " 'learning_rate': 0.07407206}\n",
            "I1224 19:41:00.765592 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.1467912,\n",
            " 'Loss/localization_loss': 0.1008444,\n",
            " 'Loss/regularization_loss': 0.12395141,\n",
            " 'Loss/total_loss': 0.37158704,\n",
            " 'learning_rate': 0.07407206}\n",
            "INFO:tensorflow:Step 9700 per-step time 1.540s\n",
            "I1224 19:43:34.740289 132534240645120 model_lib_v2.py:705] Step 9700 per-step time 1.540s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.11714307,\n",
            " 'Loss/localization_loss': 0.084193215,\n",
            " 'Loss/regularization_loss': 0.123495154,\n",
            " 'Loss/total_loss': 0.32483143,\n",
            " 'learning_rate': 0.073937014}\n",
            "I1224 19:43:34.740785 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.11714307,\n",
            " 'Loss/localization_loss': 0.084193215,\n",
            " 'Loss/regularization_loss': 0.123495154,\n",
            " 'Loss/total_loss': 0.32483143,\n",
            " 'learning_rate': 0.073937014}\n",
            "INFO:tensorflow:Step 9800 per-step time 1.582s\n",
            "I1224 19:46:12.982715 132534240645120 model_lib_v2.py:705] Step 9800 per-step time 1.582s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.141473,\n",
            " 'Loss/localization_loss': 0.035655234,\n",
            " 'Loss/regularization_loss': 0.12305899,\n",
            " 'Loss/total_loss': 0.3001872,\n",
            " 'learning_rate': 0.07380057}\n",
            "I1224 19:46:12.983241 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.141473,\n",
            " 'Loss/localization_loss': 0.035655234,\n",
            " 'Loss/regularization_loss': 0.12305899,\n",
            " 'Loss/total_loss': 0.3001872,\n",
            " 'learning_rate': 0.07380057}\n",
            "INFO:tensorflow:Step 9900 per-step time 1.570s\n",
            "I1224 19:48:50.006340 132534240645120 model_lib_v2.py:705] Step 9900 per-step time 1.570s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.10927893,\n",
            " 'Loss/localization_loss': 0.07345078,\n",
            " 'Loss/regularization_loss': 0.12264077,\n",
            " 'Loss/total_loss': 0.30537048,\n",
            " 'learning_rate': 0.073662736}\n",
            "I1224 19:48:50.006733 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.10927893,\n",
            " 'Loss/localization_loss': 0.07345078,\n",
            " 'Loss/regularization_loss': 0.12264077,\n",
            " 'Loss/total_loss': 0.30537048,\n",
            " 'learning_rate': 0.073662736}\n",
            "INFO:tensorflow:Step 10000 per-step time 1.536s\n",
            "I1224 19:51:23.587352 132534240645120 model_lib_v2.py:705] Step 10000 per-step time 1.536s\n",
            "INFO:tensorflow:{'Loss/classification_loss': 0.083447866,\n",
            " 'Loss/localization_loss': 0.06577964,\n",
            " 'Loss/regularization_loss': 0.12228355,\n",
            " 'Loss/total_loss': 0.27151108,\n",
            " 'learning_rate': 0.07352352}\n",
            "I1224 19:51:23.587752 132534240645120 model_lib_v2.py:708] {'Loss/classification_loss': 0.083447866,\n",
            " 'Loss/localization_loss': 0.06577964,\n",
            " 'Loss/regularization_loss': 0.12228355,\n",
            " 'Loss/total_loss': 0.27151108,\n",
            " 'learning_rate': 0.07352352}\n"
          ]
        }
      ],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_YRZu7npfDH"
      },
      "source": [
        "# 7. Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80L7-fdPpfDH"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYsgEPx9pfDH"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqTV2jGBpfDH"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orvRk02UpfDI"
      },
      "source": [
        "# 8. Load Train Model From Checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TYk4_oIpfDI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as viz_utils\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRBMI6w5tr3B"
      },
      "outputs": [],
      "source": [
        "# Prevent GPU complete consumption\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        tf.config.experimental.set_virtual_device_configuration(\n",
        "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
        "    except RunTimeError as e:\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDnQg-cYpfDI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "36db29b9-d13d-43b8-d8b4-c680bb05ee1a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-c8a430a57496>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load pipeline config and build a detection model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mconfigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_configs_from_pipeline_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'PIPELINE_CONFIG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdetection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_builder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Restore checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'config_util' is not defined"
          ]
        }
      ],
      "source": [
        "# Load pipeline config and build a detection model\n",
        "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
        "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
        "\n",
        "# Restore checkpoint\n",
        "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
        "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-5')).expect_partial()\n",
        "\n",
        "@tf.function\n",
        "def detect_fn(image):\n",
        "    image, shapes = detection_model.preprocess(image)\n",
        "    prediction_dict = detection_model.predict(image, shapes)\n",
        "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
        "    return detections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EmsmbBZpfDI"
      },
      "source": [
        "# 9. Detect from an Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_MKiuZ4pfDI"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBDbIhNapfDI"
      },
      "outputs": [],
      "source": [
        "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lx3crOhOzITB"
      },
      "outputs": [],
      "source": [
        "IMAGE_PATH = os.path.join(paths['IMAGE_PATH'], 'testimg2.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpzn1SMry1yK"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(IMAGE_PATH)\n",
        "image_np = np.array(img)\n",
        "\n",
        "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "detections = detect_fn(input_tensor)\n",
        "\n",
        "num_detections = int(detections.pop('num_detections'))\n",
        "detections = {key: value[0, :num_detections].numpy()\n",
        "              for key, value in detections.items()}\n",
        "detections['num_detections'] = num_detections\n",
        "\n",
        "# detection_classes should be ints.\n",
        "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "label_id_offset = 1\n",
        "image_np_with_detections = image_np.copy()\n",
        "\n",
        "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "            image_np_with_detections,\n",
        "            detections['detection_boxes'],\n",
        "            detections['detection_classes']+label_id_offset,\n",
        "            detections['detection_scores'],\n",
        "            category_index,\n",
        "            use_normalized_coordinates=True,\n",
        "            max_boxes_to_draw=5,\n",
        "            min_score_thresh=.8,\n",
        "            agnostic_mode=False)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLRUBZXttr3C"
      },
      "outputs": [],
      "source": [
        "detections.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Ysk66Str3C"
      },
      "source": [
        "# Apply OCR to Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tDsWsEEytr3C"
      },
      "outputs": [],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cHahwwfPtr3C"
      },
      "outputs": [],
      "source": [
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio===0.8.1 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auNaNkHttr3C"
      },
      "outputs": [],
      "source": [
        "import easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tSBG_lqCtr3C"
      },
      "outputs": [],
      "source": [
        "detection_threshold = 0.7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Guko0Hyktr3C"
      },
      "outputs": [],
      "source": [
        "image = image_np_with_detections\n",
        "scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
        "boxes = detections['detection_boxes'][:len(scores)]\n",
        "classes = detections['detection_classes'][:len(scores)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fv6kJLVPtr3D"
      },
      "outputs": [],
      "source": [
        "width = image.shape[1]\n",
        "height = image.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7AbHVs7tr3D"
      },
      "outputs": [],
      "source": [
        "# Apply ROI filtering and OCR\n",
        "for idx, box in enumerate(boxes):\n",
        "    print(box)\n",
        "    roi = box*[height, width, height, width]\n",
        "    print(roi)\n",
        "    region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
        "    reader = easyocr.Reader(['en'])\n",
        "    ocr_result = reader.readtext(region)\n",
        "    print(ocr_result)\n",
        "    plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2rcfIeOZtr3D"
      },
      "outputs": [],
      "source": [
        "for result in ocr_result:\n",
        "    print(np.sum(np.subtract(result[0][2],result[0][1])))\n",
        "    print(result[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YRJ34vYtr3D"
      },
      "source": [
        "# OCR Filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USBlUxewtr3D"
      },
      "outputs": [],
      "source": [
        "region_threshold = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teFWZQA9tr3D"
      },
      "outputs": [],
      "source": [
        "def filter_text(region, ocr_result, region_threshold):\n",
        "    rectangle_size = region.shape[0]*region.shape[1]\n",
        "\n",
        "    plate = []\n",
        "    for result in ocr_result:\n",
        "        length = np.sum(np.subtract(result[0][1], result[0][0]))\n",
        "        height = np.sum(np.subtract(result[0][2], result[0][1]))\n",
        "\n",
        "        if length*height / rectangle_size > region_threshold:\n",
        "            plate.append(result[1])\n",
        "    return plate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMO_xrLDtr3D"
      },
      "outputs": [],
      "source": [
        "filter_text(region, ocr_result, region_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tj3YQwjmtr3D"
      },
      "source": [
        "# Bring it Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWL0O2Xbtr3D"
      },
      "outputs": [],
      "source": [
        "region_threshold = 0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JtnlhP8tr3D"
      },
      "outputs": [],
      "source": [
        "def ocr_it(image, detections, detection_threshold, region_threshold):\n",
        "\n",
        "    # Scores, boxes and classes above threhold\n",
        "    scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
        "    boxes = detections['detection_boxes'][:len(scores)]\n",
        "    classes = detections['detection_classes'][:len(scores)]\n",
        "\n",
        "    # Full image dimensions\n",
        "    width = image.shape[1]\n",
        "    height = image.shape[0]\n",
        "\n",
        "    # Apply ROI filtering and OCR\n",
        "    for idx, box in enumerate(boxes):\n",
        "        roi = box*[height, width, height, width]\n",
        "        region = image[int(roi[0]):int(roi[2]),int(roi[1]):int(roi[3])]\n",
        "        reader = easyocr.Reader(['en'])\n",
        "        ocr_result = reader.readtext(region)\n",
        "\n",
        "        text = filter_text(region, ocr_result, region_threshold)\n",
        "\n",
        "        plt.imshow(cv2.cvtColor(region, cv2.COLOR_BGR2RGB))\n",
        "        plt.show()\n",
        "        print(text)\n",
        "        return text, region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jx7hwo_ktr3E"
      },
      "outputs": [],
      "source": [
        "text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kCuEhTNtr3E"
      },
      "source": [
        "# Save Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w_qgNDttr3E"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import uuid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFzkGypKtr3E"
      },
      "outputs": [],
      "source": [
        "'{}.jpg'.format(uuid.uuid1())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fg23PRYHtr3E"
      },
      "outputs": [],
      "source": [
        "def save_results(text, region, csv_filename, folder_path):\n",
        "    img_name = '{}.jpg'.format(uuid.uuid1())\n",
        "\n",
        "    cv2.imwrite(os.path.join(folder_path, img_name), region)\n",
        "\n",
        "    with open(csv_filename, mode='a', newline='') as f:\n",
        "        csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        csv_writer.writerow([img_name, text])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTDNoxxWtr3F"
      },
      "outputs": [],
      "source": [
        "region"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGDJk8oatr3F"
      },
      "outputs": [],
      "source": [
        "save_results(text, region, 'detection_results.csv', 'Detection_Images')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsNAaYAo0WVL"
      },
      "source": [
        "# 10. Real Time Detections from your Webcam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igR2rw76tr3F"
      },
      "outputs": [],
      "source": [
        "!pip uninstall opencv-python-headless -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_grs6OGpfDJ"
      },
      "outputs": [],
      "source": [
        "cap = cv2.VideoCapture(0)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    image_np = np.array(frame)\n",
        "\n",
        "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
        "    detections = detect_fn(input_tensor)\n",
        "\n",
        "    num_detections = int(detections.pop('num_detections'))\n",
        "    detections = {key: value[0, :num_detections].numpy()\n",
        "                  for key, value in detections.items()}\n",
        "    detections['num_detections'] = num_detections\n",
        "\n",
        "    # detection_classes should be ints.\n",
        "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
        "\n",
        "    label_id_offset = 1\n",
        "    image_np_with_detections = image_np.copy()\n",
        "\n",
        "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
        "                image_np_with_detections,\n",
        "                detections['detection_boxes'],\n",
        "                detections['detection_classes']+label_id_offset,\n",
        "                detections['detection_scores'],\n",
        "                category_index,\n",
        "                use_normalized_coordinates=True,\n",
        "                max_boxes_to_draw=5,\n",
        "                min_score_thresh=.8,\n",
        "                agnostic_mode=False)\n",
        "\n",
        "    try:\n",
        "        text, region = ocr_it(image_np_with_detections, detections, detection_threshold, region_threshold)\n",
        "        save_results(text, region, 'realtimeresults.csv', 'Detection_Images')\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
        "\n",
        "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzlM4jt0pfDJ"
      },
      "source": [
        "# 10. Freezing the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4olHB2npfDJ"
      },
      "outputs": [],
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AjO93QDpfDJ"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6Lsp3tCpfDJ"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Sw1ULgHpfDJ"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTPmdqaXpfDK"
      },
      "source": [
        "# 11. Conversion to TFJS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZ6UzY_fpfDK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!pip install tensorflowjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oxbVynHpfDK"
      },
      "outputs": [],
      "source": [
        "command = \"tensorflowjs_converter --input_format=tf_saved_model --output_node_names='detection_boxes,detection_classes,detection_features,detection_multiclass_scores,detection_scores,num_detections,raw_detection_boxes,raw_detection_scores' --output_format=tfjs_graph_model --signature_name=serving_default {} {}\".format(os.path.join(paths['OUTPUT_PATH'], 'saved_model'), paths['TFJS_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB2AGNmJpfDK"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7rfT4-hpfDK"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o8_hm-itpfDK"
      },
      "outputs": [],
      "source": [
        "# Test Code: https://github.com/nicknochnack/RealTimeSignLanguageDetectionwithTFJS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtUw73FHpfDK"
      },
      "source": [
        "# 12. Conversion to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XviMtewLpfDK"
      },
      "outputs": [],
      "source": [
        "TFLITE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us86cjC4pfDL"
      },
      "outputs": [],
      "source": [
        "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(TFLITE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['TFLITE_PATH'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n1r5YO3rpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-xWpHN8pfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJfYMbN6pfDL"
      },
      "outputs": [],
      "source": [
        "FROZEN_TFLITE_PATH = os.path.join(paths['TFLITE_PATH'], 'saved_model')\n",
        "TFLITE_MODEL = os.path.join(paths['TFLITE_PATH'], 'saved_model', 'detect.tflite')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBgfBzACtr3H"
      },
      "outputs": [],
      "source": [
        "command = \"tflite_convert \\\n",
        "--saved_model_dir={} \\\n",
        "--output_file={} \\\n",
        "--input_shapes=1,300,300,3 \\\n",
        "--input_arrays=normalized_input_image_tensor \\\n",
        "--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\n",
        "--inference_type=FLOAT \\\n",
        "--allow_custom_ops\".format(FROZEN_TFLITE_PATH, TFLITE_MODEL, )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E8GwUeoFpfDL"
      },
      "outputs": [],
      "source": [
        "print(command)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nbd7gqHMpfDL"
      },
      "outputs": [],
      "source": [
        "!{command}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NQqZRdA21Uc"
      },
      "source": [
        "# 13. Zip and Export Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTVTGCQp2ZJJ"
      },
      "outputs": [],
      "source": [
        "!tar -czf models.tar.gz {paths['CHECKPOINT_PATH']}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whShhB0x3PYJ",
        "outputId": "87b870e3-55a1-48ff-cb6a-29ff83baaab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "anprsys",
      "language": "python",
      "name": "anprsys"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}